{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atYs6B3_U4Sp"
      },
      "source": [
        "#Initial Installs"
      ],
      "id": "atYs6B3_U4Sp"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QTZGaZTlekfM",
        "outputId": "88afb140-9284-4508-b83b-4fa62a841d46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "â¬ Downloading https://github.com/jaimergp/miniforge/releases/latest/download/Mambaforge-colab-Linux-x86_64.sh...\n",
            "ðŸ“¦ Installing...\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()\n",
        "!conda --version\n",
        "!conda install ffmpeg=4.3 -c conda-forge\n",
        "!conda install mlflow\n",
        "!pip install pyngrok --quiet\n",
        "!pip install audiomentations"
      ],
      "id": "QTZGaZTlekfM"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTUY08GwDCkC"
      },
      "source": [
        "# Initial Imports, Mount Drive\n"
      ],
      "id": "bTUY08GwDCkC"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fca948dc",
        "outputId": "747a0e6f-9946-4cf7-dccd-d64e68b7f687"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "# Initial imports\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "# needed to install torch like so:\n",
        "#         pip3 install torch torchvision torchaudio\n",
        "import tensorflow as tf # this needs to happen before any torch imports....\n",
        "import torchaudio\n",
        "import os\n",
        "\n",
        "import librosa\n",
        "import matplotlib.pyplot as plt\n",
        "#import requests\n",
        "from IPython.display import Audio, display\n",
        "from google.colab import drive\n",
        "\n",
        "from collections import Counter\n",
        "from torch.utils.data import Dataset\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "import keras \n",
        "import mlflow\n",
        "import mlflow.keras\n",
        "import datetime\n",
        "\n",
        "# Mount Drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "archive_path = \"./gdrive/MyDrive/Accent_Recognition/archive\"\n",
        "recordings_path = \"./gdrive/MyDrive/Accent_Recognition/archive/recordings/recordings\"  \n"
      ],
      "id": "fca948dc"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KlLzJb_aDxRK"
      },
      "source": [
        "# Define Dataset Classes and Helper Functions"
      ],
      "id": "KlLzJb_aDxRK"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2a426af",
        "outputId": "b0cd314e-f760-41eb-a3e7-d210c425cc48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "finished defining\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchaudio/functional/functional.py:540: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (128) may be set too high. Or, the value for `n_freqs` (513) may be set too low.\n",
            "  \"At least one mel filterbank has all zero values. \"\n"
          ]
        }
      ],
      "source": [
        "############\n",
        "# Define a dataset class\n",
        "#\n",
        "# this should have methods for:\n",
        "# loading\n",
        "# preprocessing\n",
        "# filtering\n",
        "# train / test / validation splitting\n",
        "###########\n",
        "\n",
        "import torch\n",
        "\n",
        "\n",
        "# define global variagbles\n",
        "samples_per_batch = 32\n",
        "spectrogram_max_length = 7336\n",
        "number_of_mels = 128\n",
        "random_seed_number = 108\n",
        "\n",
        "random.seed(random_seed_number)\n",
        "\n",
        "def plot_spectrogram(spec, title=None, ylabel=\"freq_bin\", aspect=\"auto\", xmax=None):\n",
        "    fig, axs = plt.subplots(1, 1, figsize=(10, 8))\n",
        "    axs.set_title(title or \"Spectrogram (db)\")\n",
        "    axs.set_ylabel(ylabel)\n",
        "    axs.set_xlabel(\"frame\")\n",
        "    im = axs.imshow(librosa.power_to_db(spec), origin=\"lower\", aspect=aspect)\n",
        "    if xmax:\n",
        "        axs.set_xlim((0, xmax))\n",
        "    fig.colorbar(im, ax=axs)\n",
        "    plt.show(block=False)\n",
        "\n",
        "def play_audio(waveform, sample_rate):\n",
        "    import numpy as np\n",
        "    if not isinstance(waveform,np.ndarray):\n",
        "      waveform = waveform.numpy()\n",
        "\n",
        "    num_channels, num_frames = waveform.shape\n",
        "    if num_channels == 1:\n",
        "        display(Audio(waveform[0], rate=sample_rate))\n",
        "    elif num_channels == 2:\n",
        "        display(Audio((waveform[0], waveform[1]), rate=sample_rate))\n",
        "    else:\n",
        "        raise ValueError(\"Waveform with more than 2 channels are not supported.\")\n",
        "\n",
        "mel_spectrogram = torchaudio.transforms.MelSpectrogram(\n",
        "    sample_rate=44100,\n",
        "    n_fft=1024,\n",
        "    win_length=None,\n",
        "    hop_length=512,\n",
        "    center=True,\n",
        "    pad_mode=\"reflect\",\n",
        "    power=2.0,\n",
        "    norm=\"slaney\",\n",
        "    onesided=True,\n",
        "    n_mels=128,\n",
        "    mel_scale=\"htk\",\n",
        ")\n",
        "\n",
        "class AccentDataset(Dataset):\n",
        "    def __init__(self, audio_files_folder, metadata_file, make_spectra=False, language_samples_threshold = 30):\n",
        "        self.audio_files_folder = audio_files_folder\n",
        "        self.metadata_file = metadata_file\n",
        "        self.make_spectra = make_spectra\n",
        "        self.metadata = self.load_metadata()\n",
        "        self.language_samples_threshold = language_samples_threshold\n",
        "        self.metadata = self.filter_metadata()\n",
        "        self.audio = self.load_audio()\n",
        "        if not make_spectra:\n",
        "            self.load_spectrograms()\n",
        "        self.training_fraction = 0.67\n",
        "        self.downsample_training = True\n",
        "        self.downsampled_number = 5\n",
        "        self.train_indices, self.test_indices = self.create_train_test_split()\n",
        "        \n",
        "    def load_metadata(self):\n",
        "        metadata = pd.read_csv(self.metadata_file)\n",
        "        return metadata\n",
        "    \n",
        "    def filter_metadata(self):\n",
        "        self.metadata = self.metadata[self.metadata['file_missing?'] != True]\n",
        "        samples_per_language = Counter(self.metadata['native_language'])    \n",
        "        filtered_languages = [language for language in samples_per_language.keys() if \\\n",
        "                              samples_per_language[language] >= self.language_samples_threshold]\n",
        "        filtered_speakers = self.metadata[self.metadata['native_language'].isin(filtered_languages)]\n",
        "        return filtered_speakers\n",
        "    \n",
        "    def load_audio(self):\n",
        "        audio = {}\n",
        "        for file_index in tqdm(self.metadata.index):\n",
        "            file_name = self.metadata.loc[file_index]['filename']\n",
        "            audio_file = AudioFile(file_name, self.audio_files_folder, self.metadata.loc[file_index])\n",
        "            if self.make_spectra:\n",
        "                audio_file.make_mel_spectrogram()\n",
        "            audio[file_name] = audio_file\n",
        "        return audio\n",
        "\n",
        "    def write_spectrograms(self):\n",
        "        print(\"Writing Spectrograms to Disk\")\n",
        "        for file_index in tqdm(self.metadata.index):\n",
        "            file_name = self.metadata.loc[file_index]['filename']\n",
        "            spectrogram_file_full_path = os.path.join(os.path.dirname(self.audio_files_folder), 'Spectra', file_name)\n",
        "            np.save(spectrogram_file_full_path, self.audio[file_name].spectrogram)\n",
        "\n",
        "    def load_spectrograms(self):\n",
        "        for file_index in tqdm(self.metadata.index):\n",
        "            file_name = self.metadata.loc[file_index]['filename']\n",
        "            spectrogram_file_full_path = os.path.join(os.path.dirname(self.audio_files_folder), 'Spectra', file_name + '.npy')\n",
        "            self.audio[file_name].spectrogram = np.load(spectrogram_file_full_path)\n",
        "    \n",
        "    def create_train_test_split(self):\n",
        "        unique_languages = list(set(self.metadata['native_language']))\n",
        "        train_indices =[]\n",
        "        test_indices = []\n",
        "        for language in unique_languages:\n",
        "            this_language = self.metadata[self.metadata['native_language'] == language]\n",
        "            this_language_male = this_language[this_language['sex']=='male']\n",
        "            this_language_female = this_language[this_language['sex']=='female']\n",
        "            traininds_male = random.sample(list(this_language_male.index), \n",
        "                                           int(self.training_fraction * len(this_language_male.index)))\n",
        "            traininds_female = random.sample(list(this_language_female.index), \n",
        "                                           int(self.training_fraction * len(this_language_female.index)))\n",
        "            traininds = traininds_male + traininds_female\n",
        "            testinds = list(set(this_language.index) - set(traininds))\n",
        "            if self.downsample_training:                \n",
        "                traininds = traininds_male[:self.downsampled_number] + traininds_female[:self.downsampled_number]\n",
        "            train_indices += traininds\n",
        "            test_indices += testinds\n",
        "        return sorted(train_indices), sorted(test_indices)\n",
        "    \n",
        "    \n",
        "class AccentDatasetBatch(Dataset):\n",
        "    def __init__(self, audio_files_folder, metadata):\n",
        "        self.audio_files_folder = audio_files_folder\n",
        "        self.metadata = metadata\n",
        "        self.audio = self.load_audio()\n",
        "        self.load_spectrograms()\n",
        "\n",
        "    \n",
        "    def load_audio(self):\n",
        "        audio = {}\n",
        "        for file_index in tqdm(self.metadata.index):\n",
        "            file_name = self.metadata.loc[file_index]['filename']\n",
        "            audio_file = AudioFile(file_name, self.audio_files_folder, self.metadata.loc[file_index])\n",
        "            # if self.make_spectra:\n",
        "            #     audio_file.make_mel_spectrogram()\n",
        "            audio[file_name] = audio_file\n",
        "        return audio\n",
        "\n",
        "    def load_spectrograms(self):\n",
        "        for file_index in tqdm(self.metadata.index):\n",
        "            file_name = self.metadata.loc[file_index]['filename']\n",
        "            spectrogram_file_full_path = os.path.join(os.path.dirname(self.audio_files_folder), 'Spectra', file_name + '.npy')\n",
        "            #print(f\"loading {file_name}\")\n",
        "            self.audio[file_name].spectrogram = np.load(spectrogram_file_full_path)\n",
        "\n",
        "\n",
        "class AudioFile(object):\n",
        "    def __init__(self, file_name, file_path, metadata_row):\n",
        "        self.file_name = file_name\n",
        "        self.file_path = file_path\n",
        "        self.waveform = None\n",
        "        self.spectrogram = None\n",
        "        self.language = metadata_row['native_language']\n",
        "        self.age = metadata_row['age']\n",
        "        self.sex = metadata_row['sex']\n",
        "        self.metadata_row = metadata_row\n",
        "    \n",
        "    def __repr__(self):\n",
        "        return self.file_name\n",
        "        \n",
        "    def load_audio_file(self):\n",
        "        full_path = os.path.join(self.file_path, self.file_name + \".mp3\")\n",
        "        self.waveform, self.sample_rate = torchaudio.load(full_path, normalize=True)\n",
        "\n",
        "    # def mel_spectrogram(self):\n",
        "    #    return torchaudio.transforms.MelSpectrogram(\n",
        "    #         sample_rate=44100,\n",
        "    #         n_fft=1024,\n",
        "    #         win_length=None,\n",
        "    #         hop_length=512,\n",
        "    #         center=True,\n",
        "    #         pad_mode=\"reflect\",\n",
        "    #         power=2.0,\n",
        "    #         norm=\"slaney\",\n",
        "    #         onesided=True,\n",
        "    #         n_mels=128,\n",
        "    #         mel_scale=\"htk\",\n",
        "    #     )\n",
        "    \n",
        "    def make_mel_spectrogram(self, \n",
        "                             n_fft = 1024, \n",
        "                             win_length = None, \n",
        "                             hop_length = 512, \n",
        "                             n_mels = 128):\n",
        "        mel_spectrogram = torchaudio.transforms.MelSpectrogram(\n",
        "            sample_rate=44100,\n",
        "            n_fft=n_fft,\n",
        "            win_length=win_length,\n",
        "            hop_length=hop_length,\n",
        "            center=True,\n",
        "            pad_mode=\"reflect\",\n",
        "            power=2.0,\n",
        "            norm=\"slaney\",\n",
        "            onesided=True,\n",
        "            n_mels=n_mels,\n",
        "            mel_scale=\"htk\",\n",
        "        )\n",
        "        if self.waveform is None:\n",
        "            self.load_audio_file()\n",
        "        if isinstance(self.waveform, np.ndarray):\n",
        "          self.spectrogram = mel_spectrogram(torch.from_numpy(self.waveform))\n",
        "        else:\n",
        "          self.spectrogram = mel_spectrogram(self.waveform)\n",
        "    \n",
        "    def plot_spectrogram(self):\n",
        "        if self.spectrogram is None:\n",
        "            self.spectrogram = mel_spectrogram(self.waveform)\n",
        "        plot_spectrogram(self.spectrogram[0,:,:200], title=self.file_name)\n",
        "        plot_spectrogram(self.spectrogram[0], title=self.file_name)\n",
        "    \n",
        "    def play_recording(self):\n",
        "        play_audio(self.waveform, self.sample_rate)\n",
        "    \n",
        "print(\"finished defining\")"
      ],
      "id": "c2a426af"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hfp_Sk6qD6ro"
      },
      "source": [
        "# Write Spectra to Disk, Display Examples, One Time Only"
      ],
      "id": "hfp_Sk6qD6ro"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMA363kFN8Yi",
        "outputId": "aecbbff7-062a-422e-beda-b76ced82feab"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1768/1768 [11:46<00:00,  2.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing Spectrograms to Disk\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1768/1768 [00:22<00:00, 76.94it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DONE\n",
            "['english241.npy', 'english242.npy', 'english243.npy', 'english244.npy', 'english245.npy', 'english246.npy', 'english247.npy', 'english248.npy', 'english249.npy', 'english25.npy', 'english250.npy', 'english251.npy', 'english252.npy', 'english253.npy', 'english254.npy', 'english255.npy', 'english256.npy', 'english257.npy', 'english258.npy', 'english259.npy', 'english26.npy', 'english260.npy', 'english261.npy', 'english262.npy', 'english263.npy', 'english264.npy', 'english265.npy', 'english266.npy', 'english267.npy', 'english268.npy', 'english269.npy', 'english27.npy', 'english270.npy', 'english271.npy', 'english272.npy', 'english273.npy', 'english274.npy', 'english275.npy', 'english276.npy', 'english277.npy', 'english278.npy', 'english279.npy', 'english28.npy', 'english280.npy', 'english281.npy', 'english282.npy', 'english283.npy', 'english284.npy', 'english285.npy', 'english286.npy', 'english287.npy', 'english288.npy', 'english289.npy', 'english29.npy', 'english290.npy', 'english291.npy', 'english292.npy', 'english293.npy', 'english294.npy', 'english295.npy', 'english296.npy', 'english297.npy', 'english298.npy', 'english299.npy', 'english3.npy', 'english30.npy', 'english300.npy', 'english301.npy', 'english302.npy', 'english303.npy', 'english304.npy', 'english305.npy', 'english306.npy', 'english307.npy', 'english308.npy', 'english309.npy', 'english31.npy', 'english310.npy', 'english311.npy', 'english312.npy', 'english313.npy', 'english314.npy', 'english315.npy', 'english316.npy', 'english317.npy', 'english318.npy', 'english319.npy', 'english32.npy', 'english320.npy', 'english321.npy', 'english322.npy', 'english323.npy', 'english324.npy', 'english325.npy', 'english326.npy', 'english327.npy', 'english328.npy', 'english329.npy', 'english33.npy', 'english330.npy', 'english331.npy', 'english332.npy', 'english333.npy', 'english334.npy', 'english335.npy', 'english336.npy', 'english337.npy', 'english338.npy', 'english339.npy', 'english34.npy', 'english340.npy', 'english341.npy', 'english342.npy', 'english343.npy', 'english344.npy', 'english345.npy', 'english346.npy', 'english347.npy', 'english348.npy', 'english349.npy', 'english35.npy', 'english350.npy', 'english351.npy', 'english352.npy', 'english353.npy', 'english354.npy', 'english355.npy', 'english356.npy', 'english357.npy', 'english358.npy', 'english359.npy', 'english36.npy', 'english360.npy', 'english361.npy', 'english362.npy', 'english363.npy', 'english364.npy', 'english365.npy', 'english366.npy', 'english367.npy', 'english368.npy', 'arabic1.npy', 'english369.npy', 'english37.npy', 'english370.npy', 'english371.npy', 'english372.npy', 'english373.npy', 'english374.npy', 'english375.npy', 'english376.npy', 'english377.npy', 'english378.npy', 'english379.npy', 'english38.npy', 'english380.npy', 'english381.npy', 'english382.npy', 'english383.npy', 'english384.npy', 'english385.npy', 'english386.npy', 'english387.npy', 'english388.npy', 'english389.npy', 'english39.npy', 'english390.npy', 'english391.npy', 'english392.npy', 'english393.npy', 'english394.npy', 'english395.npy', 'english396.npy', 'english397.npy', 'english398.npy', 'english399.npy', 'english4.npy', 'english40.npy', 'english400.npy', 'english401.npy', 'english402.npy', 'english403.npy', 'english404.npy', 'english405.npy', 'english406.npy', 'english407.npy', 'english408.npy', 'english409.npy', 'english41.npy', 'english410.npy', 'english411.npy', 'english412.npy', 'english413.npy', 'english414.npy', 'english415.npy', 'english416.npy', 'english417.npy', 'english418.npy', 'english419.npy', 'english42.npy', 'english420.npy', 'english421.npy', 'english422.npy', 'english423.npy', 'english424.npy', 'english425.npy', 'english426.npy', 'english427.npy', 'english428.npy', 'english429.npy', 'english43.npy', 'english430.npy', 'english431.npy', 'english432.npy', 'english433.npy', 'english434.npy', 'english435.npy', 'english436.npy', 'english437.npy', 'english438.npy', 'english439.npy', 'english44.npy', 'english440.npy', 'english441.npy', 'english442.npy', 'english443.npy', 'english444.npy', 'english445.npy', 'english446.npy', 'english447.npy', 'english448.npy', 'english449.npy', 'english45.npy', 'english450.npy', 'english451.npy', 'english452.npy', 'english453.npy', 'english454.npy', 'english455.npy', 'english456.npy', 'english457.npy', 'english458.npy', 'english459.npy', 'english46.npy', 'english460.npy', 'english461.npy', 'english462.npy', 'english463.npy', 'english464.npy', 'english465.npy', 'english466.npy', 'english467.npy', 'english468.npy', 'english469.npy', 'english47.npy', 'english470.npy', 'english471.npy', 'english472.npy', 'english473.npy', 'english474.npy', 'english475.npy', 'english476.npy', 'english477.npy', 'english478.npy', 'english479.npy', 'english48.npy', 'english480.npy', 'english481.npy', 'english482.npy', 'english483.npy', 'english484.npy', 'english485.npy', 'english486.npy', 'english487.npy', 'english488.npy', 'english489.npy', 'english49.npy', 'english490.npy', 'english491.npy', 'english492.npy', 'english493.npy', 'english494.npy', 'english495.npy', 'english496.npy', 'english497.npy', 'english498.npy', 'english499.npy', 'english5.npy', 'english50.npy', 'english500.npy', 'english501.npy', 'english502.npy', 'english503.npy', 'english504.npy', 'english505.npy', 'english506.npy', 'english507.npy', 'english508.npy', 'english509.npy', 'english51.npy', 'english510.npy', 'english511.npy', 'english512.npy', 'english513.npy', 'english514.npy', 'english515.npy', 'english516.npy', 'english517.npy', 'english518.npy', 'english519.npy', 'english52.npy', 'english520.npy', 'english521.npy', 'english522.npy', 'english523.npy', 'english524.npy', 'english525.npy', 'english526.npy', 'english527.npy', 'english528.npy', 'english529.npy', 'english53.npy', 'english530.npy', 'english531.npy', 'english532.npy', 'english533.npy', 'english534.npy', 'english535.npy', 'english536.npy', 'english537.npy', 'english538.npy', 'english539.npy', 'english54.npy', 'english540.npy', 'english541.npy', 'english542.npy', 'english543.npy', 'english544.npy', 'english545.npy', 'english546.npy', 'english547.npy', 'english548.npy', 'english549.npy', 'english55.npy', 'english550.npy', 'english551.npy', 'english552.npy', 'english553.npy', 'english554.npy', 'english555.npy', 'english556.npy', 'english557.npy', 'english558.npy', 'english559.npy', 'english56.npy', 'english560.npy', 'english561.npy', 'english562.npy', 'english563.npy', 'english564.npy', 'english565.npy', 'english566.npy', 'english567.npy', 'english568.npy', 'english569.npy', 'english57.npy', 'english570.npy', 'english571.npy', 'english572.npy', 'english573.npy', 'english574.npy', 'english575.npy', 'english576.npy', 'english577.npy', 'english578.npy', 'english579.npy', 'english58.npy', 'english59.npy', 'english6.npy', 'english60.npy', 'english61.npy', 'english62.npy', 'english63.npy', 'english64.npy', 'english65.npy', 'english66.npy', 'english67.npy', 'english68.npy', 'english69.npy', 'english7.npy', 'english70.npy', 'english71.npy', 'english72.npy', 'english73.npy', 'english74.npy', 'english75.npy', 'english76.npy', 'english77.npy', 'english78.npy', 'english79.npy', 'english8.npy', 'english80.npy', 'english81.npy', 'english82.npy', 'english83.npy', 'english84.npy', 'english85.npy', 'english86.npy', 'english87.npy', 'english88.npy', 'english89.npy', 'english9.npy', 'english90.npy', 'english91.npy', 'english92.npy', 'english93.npy', 'english94.npy', 'english95.npy', 'english96.npy', 'english97.npy', 'english98.npy', 'english99.npy', 'french1.npy', 'french10.npy', 'french11.npy', 'french12.npy', 'french13.npy', 'french14.npy', 'french15.npy', 'french16.npy', 'french17.npy', 'french18.npy', 'french19.npy', 'french2.npy', 'french20.npy', 'french21.npy', 'french22.npy', 'french23.npy', 'french24.npy', 'french25.npy', 'french26.npy', 'french27.npy', 'french28.npy', 'french29.npy', 'french3.npy', 'french30.npy', 'french31.npy', 'french32.npy', 'french33.npy', 'french34.npy', 'french35.npy', 'french36.npy', 'french37.npy', 'french38.npy', 'french39.npy', 'french4.npy', 'french40.npy', 'french41.npy', 'french42.npy', 'french43.npy', 'french44.npy', 'french45.npy', 'french46.npy', 'french47.npy', 'french48.npy', 'french49.npy', 'french5.npy', 'french50.npy', 'french51.npy', 'french52.npy', 'french53.npy', 'french54.npy', 'french55.npy', 'french56.npy', 'french57.npy', 'french58.npy', 'french59.npy', 'french6.npy', 'french60.npy', 'french61.npy', 'french62.npy', 'french63.npy', 'french7.npy', 'french8.npy', 'french9.npy', 'german1.npy', 'german10.npy', 'german11.npy', 'german12.npy', 'german13.npy', 'german14.npy', 'german15.npy', 'german16.npy', 'german17.npy', 'german18.npy', 'german19.npy', 'german2.npy', 'german20.npy', 'german21.npy', 'german22.npy', 'german23.npy', 'german24.npy', 'german25.npy', 'german26.npy', 'german27.npy', 'german28.npy', 'german29.npy', 'german3.npy', 'german30.npy', 'german31.npy', 'german32.npy', 'german33.npy', 'german34.npy', 'german35.npy', 'german36.npy', 'german4.npy', 'german5.npy', 'german6.npy', 'german7.npy', 'german8.npy', 'german9.npy', 'italian1.npy', 'italian10.npy', 'italian11.npy', 'italian12.npy', 'italian13.npy', 'italian14.npy', 'italian15.npy', 'italian16.npy', 'italian17.npy', 'italian18.npy', 'italian19.npy', 'italian2.npy', 'italian20.npy', 'italian21.npy', 'italian22.npy', 'italian23.npy', 'italian24.npy', 'italian25.npy', 'italian26.npy', 'italian27.npy', 'italian28.npy', 'italian29.npy', 'italian3.npy', 'italian30.npy', 'italian31.npy', 'italian32.npy', 'italian33.npy', 'italian4.npy', 'italian5.npy', 'italian6.npy', 'italian7.npy', 'italian8.npy', 'italian9.npy', 'korean1.npy', 'korean10.npy', 'korean11.npy', 'korean12.npy', 'korean13.npy', 'korean14.npy', 'korean15.npy', 'korean16.npy', 'korean17.npy', 'korean18.npy', 'korean19.npy', 'korean2.npy', 'korean20.npy', 'korean21.npy', 'korean22.npy', 'korean23.npy', 'korean24.npy', 'korean25.npy', 'korean26.npy', 'korean27.npy', 'korean28.npy', 'korean29.npy', 'korean3.npy', 'korean30.npy', 'korean31.npy', 'korean32.npy', 'korean33.npy', 'korean34.npy', 'korean35.npy', 'korean36.npy', 'korean37.npy', 'korean38.npy', 'korean39.npy', 'korean4.npy', 'korean40.npy', 'korean41.npy', 'korean42.npy', 'korean43.npy', 'korean44.npy', 'korean45.npy', 'korean46.npy', 'korean47.npy', 'korean48.npy', 'korean49.npy', 'korean5.npy', 'korean50.npy', 'korean51.npy', 'korean52.npy', 'korean6.npy', 'korean7.npy', 'korean8.npy', 'korean9.npy', 'mandarin1.npy', 'mandarin10.npy', 'mandarin11.npy', 'mandarin12.npy', 'mandarin13.npy', 'mandarin14.npy', 'mandarin15.npy', 'mandarin16.npy', 'mandarin17.npy', 'mandarin18.npy', 'mandarin19.npy', 'mandarin2.npy', 'mandarin20.npy', 'mandarin21.npy', 'mandarin22.npy', 'mandarin23.npy', 'mandarin24.npy', 'mandarin25.npy', 'mandarin26.npy', 'mandarin27.npy', 'mandarin28.npy', 'mandarin29.npy', 'mandarin3.npy', 'mandarin30.npy', 'mandarin31.npy', 'mandarin32.npy', 'mandarin33.npy', 'mandarin34.npy', 'mandarin35.npy', 'mandarin36.npy', 'mandarin37.npy', 'mandarin38.npy', 'mandarin39.npy', 'mandarin4.npy', 'mandarin40.npy', 'mandarin41.npy', 'mandarin42.npy', 'mandarin43.npy', 'mandarin44.npy', 'mandarin45.npy', 'mandarin46.npy', 'mandarin47.npy', 'mandarin48.npy', 'mandarin49.npy', 'mandarin5.npy', 'mandarin50.npy', 'mandarin51.npy', 'mandarin52.npy', 'mandarin53.npy', 'mandarin54.npy', 'mandarin55.npy', 'mandarin56.npy', 'mandarin57.npy', 'mandarin58.npy', 'mandarin59.npy', 'mandarin6.npy', 'mandarin60.npy', 'mandarin61.npy', 'mandarin62.npy', 'mandarin63.npy', 'mandarin64.npy', 'mandarin65.npy', 'mandarin7.npy', 'mandarin8.npy', 'mandarin9.npy', 'polish1.npy', 'polish10.npy', 'polish11.npy', 'polish12.npy', 'polish13.npy', 'polish14.npy', 'polish15.npy', 'polish16.npy', 'polish17.npy', 'polish18.npy', 'polish19.npy', 'polish2.npy', 'polish20.npy', 'polish21.npy', 'polish22.npy', 'polish23.npy', 'polish24.npy', 'polish25.npy', 'polish26.npy', 'polish27.npy', 'polish28.npy', 'polish29.npy', 'polish3.npy', 'polish30.npy', 'polish31.npy', 'polish32.npy', 'polish33.npy', 'polish34.npy', 'polish4.npy', 'polish5.npy', 'polish6.npy', 'polish7.npy', 'polish8.npy', 'polish9.npy', 'portuguese1.npy', 'portuguese10.npy', 'portuguese11.npy', 'portuguese12.npy', 'portuguese13.npy', 'portuguese14.npy', 'portuguese15.npy', 'portuguese16.npy', 'portuguese17.npy', 'portuguese18.npy', 'portuguese19.npy', 'portuguese2.npy', 'portuguese20.npy', 'portuguese21.npy', 'portuguese22.npy', 'portuguese23.npy', 'portuguese24.npy', 'portuguese25.npy', 'portuguese26.npy', 'portuguese27.npy', 'portuguese28.npy', 'portuguese29.npy', 'portuguese3.npy', 'portuguese30.npy', 'portuguese31.npy', 'portuguese32.npy', 'portuguese33.npy', 'portuguese34.npy', 'portuguese35.npy', 'portuguese36.npy', 'portuguese37.npy', 'portuguese38.npy', 'portuguese39.npy', 'portuguese4.npy', 'portuguese40.npy', 'portuguese41.npy', 'portuguese42.npy', 'portuguese43.npy', 'portuguese44.npy', 'portuguese45.npy', 'portuguese46.npy', 'portuguese47.npy', 'portuguese48.npy', 'portuguese5.npy', 'portuguese6.npy', 'portuguese7.npy', 'portuguese8.npy', 'portuguese9.npy', 'russian1.npy', 'russian10.npy', 'russian11.npy', 'russian12.npy', 'russian13.npy', 'russian14.npy', 'russian15.npy', 'russian16.npy', 'russian17.npy', 'russian18.npy', 'russian19.npy', 'russian2.npy', 'russian20.npy', 'russian21.npy', 'russian22.npy', 'russian23.npy', 'russian24.npy', 'russian25.npy', 'russian26.npy', 'russian27.npy', 'russian28.npy', 'russian29.npy', 'russian3.npy', 'russian30.npy', 'russian31.npy', 'russian32.npy', 'russian33.npy', 'russian34.npy', 'russian35.npy', 'russian36.npy', 'russian37.npy', 'russian38.npy', 'russian39.npy', 'russian4.npy', 'russian40.npy', 'russian41.npy', 'russian42.npy', 'russian43.npy', 'russian44.npy', 'russian45.npy', 'russian46.npy', 'russian47.npy', 'russian48.npy', 'russian5.npy', 'russian6.npy', 'russian7.npy', 'russian8.npy', 'russian9.npy', 'spanish1.npy', 'spanish10.npy', 'spanish100.npy', 'spanish101.npy', 'spanish102.npy', 'spanish103.npy', 'spanish104.npy', 'spanish105.npy', 'spanish106.npy', 'spanish107.npy', 'spanish108.npy', 'spanish109.npy', 'spanish11.npy', 'spanish110.npy', 'spanish111.npy', 'spanish112.npy', 'spanish113.npy', 'spanish114.npy', 'spanish115.npy', 'spanish116.npy', 'spanish117.npy', 'spanish118.npy', 'spanish119.npy', 'spanish12.npy', 'spanish120.npy', 'spanish121.npy', 'spanish122.npy', 'spanish123.npy', 'spanish124.npy', 'spanish125.npy', 'spanish126.npy', 'spanish127.npy', 'spanish128.npy', 'spanish129.npy', 'spanish13.npy', 'spanish130.npy', 'spanish131.npy', 'spanish132.npy', 'spanish133.npy', 'spanish134.npy', 'spanish135.npy', 'spanish136.npy', 'spanish137.npy', 'spanish138.npy', 'spanish139.npy', 'spanish14.npy', 'spanish140.npy', 'spanish141.npy', 'spanish142.npy', 'spanish143.npy', 'spanish144.npy', 'spanish145.npy', 'spanish146.npy', 'spanish147.npy', 'spanish148.npy', 'spanish149.npy', 'spanish15.npy', 'spanish150.npy', 'spanish151.npy', 'spanish152.npy', 'spanish153.npy', 'spanish154.npy', 'spanish155.npy', 'spanish156.npy', 'spanish157.npy', 'spanish158.npy', 'spanish159.npy', 'spanish16.npy', 'spanish160.npy', 'spanish161.npy', 'spanish162.npy', 'spanish17.npy', 'spanish18.npy', 'spanish19.npy', 'spanish2.npy', 'spanish20.npy', 'spanish21.npy', 'spanish22.npy', 'spanish23.npy', 'spanish24.npy', 'spanish25.npy', 'spanish26.npy', 'spanish27.npy', 'spanish28.npy', 'spanish29.npy', 'spanish3.npy', 'spanish30.npy', 'spanish31.npy', 'spanish32.npy', 'spanish33.npy', 'spanish34.npy', 'spanish35.npy', 'spanish36.npy', 'spanish37.npy', 'spanish38.npy', 'spanish39.npy', 'spanish4.npy', 'spanish40.npy', 'spanish41.npy', 'spanish42.npy', 'spanish43.npy', 'spanish44.npy', 'spanish45.npy', 'spanish46.npy', 'spanish47.npy', 'spanish48.npy', 'spanish49.npy', 'spanish5.npy', 'spanish50.npy', 'spanish51.npy', 'spanish52.npy', 'spanish53.npy', 'spanish54.npy', 'spanish55.npy', 'spanish56.npy', 'spanish57.npy', 'spanish58.npy', 'spanish59.npy', 'spanish6.npy', 'spanish60.npy', 'spanish61.npy', 'spanish62.npy', 'spanish63.npy', 'spanish64.npy', 'spanish65.npy', 'spanish66.npy', 'spanish67.npy', 'spanish68.npy', 'spanish69.npy', 'spanish7.npy', 'spanish70.npy', 'spanish71.npy', 'spanish72.npy', 'spanish73.npy', 'spanish74.npy', 'spanish75.npy', 'spanish76.npy', 'spanish77.npy', 'spanish78.npy', 'spanish79.npy', 'spanish8.npy', 'spanish80.npy', 'spanish81.npy', 'spanish82.npy', 'spanish83.npy', 'spanish84.npy', 'spanish85.npy', 'spanish86.npy', 'spanish87.npy', 'spanish88.npy', 'spanish89.npy', 'spanish9.npy', 'spanish90.npy', 'spanish91.npy', 'spanish92.npy', 'spanish93.npy', 'spanish94.npy', 'spanish95.npy', 'spanish96.npy', 'spanish97.npy', 'spanish98.npy', 'spanish99.npy', 'turkish1.npy', 'turkish10.npy', 'turkish11.npy', 'turkish12.npy', 'turkish13.npy', 'turkish14.npy', 'turkish15.npy', 'turkish16.npy', 'turkish17.npy', 'turkish18.npy', 'turkish19.npy', 'turkish2.npy', 'turkish20.npy', 'turkish21.npy', 'turkish22.npy', 'turkish23.npy', 'turkish24.npy', 'turkish25.npy', 'turkish26.npy', 'turkish27.npy', 'turkish28.npy', 'turkish29.npy', 'turkish3.npy', 'turkish30.npy', 'turkish31.npy', 'turkish32.npy', 'turkish33.npy', 'turkish34.npy', 'turkish35.npy', 'turkish36.npy', 'turkish37.npy', 'turkish4.npy', 'turkish5.npy', 'turkish6.npy', 'turkish7.npy', 'turkish8.npy', 'turkish9.npy', 'arabic10.npy', 'arabic100.npy', 'arabic101.npy', 'arabic102.npy', 'arabic11.npy', 'arabic12.npy', 'arabic13.npy', 'arabic14.npy', 'arabic15.npy', 'arabic16.npy', 'arabic17.npy', 'arabic18.npy', 'arabic19.npy', 'arabic2.npy', 'arabic20.npy', 'arabic21.npy', 'arabic22.npy', 'arabic23.npy', 'arabic24.npy', 'arabic25.npy', 'arabic26.npy', 'arabic27.npy', 'arabic28.npy', 'arabic29.npy', 'arabic3.npy', 'arabic30.npy', 'arabic31.npy', 'arabic32.npy', 'arabic33.npy', 'arabic34.npy', 'arabic35.npy', 'arabic36.npy', 'arabic37.npy', 'arabic38.npy', 'arabic39.npy', 'arabic4.npy', 'arabic40.npy', 'arabic41.npy', 'arabic42.npy', 'arabic43.npy', 'arabic44.npy', 'arabic45.npy', 'arabic46.npy', 'arabic47.npy', 'arabic48.npy', 'arabic49.npy', 'arabic5.npy', 'arabic50.npy', 'arabic51.npy', 'arabic52.npy', 'arabic53.npy', 'arabic54.npy', 'arabic55.npy', 'arabic56.npy', 'arabic57.npy', 'arabic58.npy', 'arabic59.npy', 'arabic6.npy', 'arabic60.npy', 'arabic61.npy', 'arabic62.npy', 'arabic63.npy', 'arabic64.npy', 'arabic65.npy', 'arabic66.npy', 'arabic67.npy', 'arabic68.npy', 'arabic69.npy', 'arabic7.npy', 'arabic70.npy', 'arabic71.npy', 'arabic72.npy', 'arabic73.npy', 'arabic74.npy', 'arabic75.npy', 'arabic76.npy', 'arabic77.npy', 'arabic78.npy', 'arabic79.npy', 'arabic8.npy', 'arabic80.npy', 'arabic81.npy', 'arabic82.npy', 'arabic83.npy', 'arabic84.npy', 'arabic85.npy', 'arabic86.npy', 'arabic87.npy', 'arabic88.npy', 'arabic89.npy', 'arabic9.npy', 'arabic90.npy', 'arabic91.npy', 'arabic92.npy', 'arabic93.npy', 'arabic94.npy', 'arabic95.npy', 'arabic96.npy', 'arabic97.npy', 'arabic98.npy', 'arabic99.npy', 'dutch1.npy', 'dutch10.npy', 'dutch11.npy', 'dutch12.npy', 'dutch13.npy', 'dutch14.npy', 'dutch15.npy', 'dutch16.npy', 'dutch17.npy', 'dutch18.npy', 'dutch19.npy', 'dutch2.npy', 'dutch20.npy', 'dutch21.npy', 'dutch22.npy', 'dutch23.npy', 'dutch24.npy', 'dutch25.npy', 'dutch26.npy', 'dutch27.npy', 'dutch28.npy', 'dutch29.npy', 'dutch3.npy', 'dutch30.npy', 'dutch31.npy', 'dutch32.npy', 'dutch33.npy', 'dutch34.npy', 'dutch35.npy', 'dutch36.npy', 'dutch37.npy', 'dutch38.npy', 'dutch39.npy', 'dutch4.npy', 'dutch40.npy', 'dutch41.npy', 'dutch42.npy', 'dutch43.npy', 'dutch44.npy', 'dutch45.npy', 'dutch46.npy', 'dutch47.npy', 'dutch5.npy', 'dutch6.npy', 'dutch7.npy', 'dutch8.npy', 'dutch9.npy', 'english1.npy', 'english10.npy', 'english100.npy', 'english101.npy', 'english102.npy', 'english103.npy', 'english104.npy', 'english105.npy', 'english106.npy', 'english107.npy', 'english108.npy', 'english109.npy', 'english11.npy', 'english110.npy', 'english111.npy', 'english112.npy', 'english113.npy', 'english114.npy', 'english115.npy', 'english116.npy', 'english117.npy', 'english118.npy', 'english119.npy', 'english12.npy', 'english120.npy', 'english121.npy', 'english122.npy', 'english123.npy', 'english124.npy', 'english125.npy', 'english126.npy', 'english127.npy', 'english128.npy', 'english129.npy', 'english13.npy', 'english130.npy', 'english131.npy', 'english132.npy', 'english133.npy', 'english134.npy', 'english135.npy', 'english136.npy', 'english137.npy', 'english138.npy', 'english139.npy', 'english14.npy', 'english140.npy', 'english141.npy', 'english142.npy', 'english143.npy', 'english144.npy', 'english145.npy', 'english146.npy', 'english147.npy', 'english148.npy', 'english149.npy', 'english15.npy', 'english150.npy', 'english151.npy', 'english152.npy', 'english153.npy', 'english154.npy', 'english155.npy', 'english156.npy', 'english157.npy', 'english158.npy', 'english159.npy', 'english16.npy', 'english160.npy', 'english161.npy', 'english162.npy', 'english163.npy', 'english164.npy', 'english165.npy', 'english166.npy', 'english167.npy', 'english168.npy', 'english169.npy', 'english17.npy', 'english170.npy', 'english171.npy', 'english172.npy', 'english173.npy', 'english174.npy', 'english175.npy', 'english176.npy', 'english177.npy', 'english178.npy', 'english179.npy', 'english18.npy', 'english180.npy', 'english181.npy', 'english182.npy', 'english183.npy', 'english184.npy', 'english185.npy', 'english186.npy', 'english187.npy', 'english188.npy', 'english189.npy', 'english19.npy', 'english190.npy', 'english191.npy', 'english192.npy', 'english193.npy', 'english194.npy', 'english195.npy', 'english196.npy', 'english197.npy', 'english198.npy', 'english199.npy', 'english2.npy', 'english20.npy', 'english200.npy', 'english201.npy', 'english202.npy', 'english203.npy', 'english204.npy', 'english205.npy', 'english206.npy', 'english207.npy', 'english208.npy', 'english209.npy', 'english21.npy', 'english210.npy', 'english211.npy', 'english212.npy', 'english213.npy', 'english214.npy', 'english215.npy', 'english216.npy', 'english217.npy', 'english218.npy', 'english219.npy', 'english22.npy', 'english220.npy', 'english221.npy', 'english222.npy', 'english223.npy', 'english224.npy', 'english225.npy', 'english226.npy', 'english227.npy', 'english228.npy', 'english229.npy', 'english23.npy', 'english230.npy', 'english231.npy', 'english232.npy', 'english233.npy', 'english234.npy', 'english235.npy', 'english236.npy', 'english237.npy', 'english238.npy', 'english239.npy', 'english24.npy', 'english240.npy', 'albanian1.npy', 'albanian2.npy', 'albanian3.npy', 'albanian4.npy', 'albanian5.npy', 'albanian6.npy', 'albanian7.npy', 'albanian8.npy', 'albanian9.npy', 'amharic1.npy', 'amharic10.npy', 'amharic11.npy', 'amharic12.npy', 'amharic13.npy', 'amharic14.npy', 'amharic15.npy', 'amharic16.npy', 'amharic17.npy', 'amharic18.npy', 'amharic19.npy', 'amharic2.npy', 'amharic20.npy', 'amharic3.npy', 'amharic4.npy', 'amharic5.npy', 'amharic6.npy', 'amharic7.npy', 'amharic8.npy', 'amharic9.npy', 'bengali1.npy', 'bengali10.npy', 'bengali11.npy', 'bengali12.npy', 'bengali13.npy', 'bengali14.npy', 'bengali15.npy', 'bengali16.npy', 'bengali17.npy', 'bengali2.npy', 'bengali3.npy', 'bengali4.npy', 'bengali5.npy', 'bengali6.npy', 'bengali7.npy', 'bengali8.npy', 'bengali9.npy', 'bosnian1.npy', 'bosnian2.npy', 'bosnian3.npy', 'bosnian4.npy', 'bosnian5.npy', 'bosnian6.npy', 'bosnian7.npy', 'bosnian8.npy', 'bosnian9.npy', 'bulgarian1.npy', 'bulgarian10.npy', 'bulgarian11.npy', 'bulgarian12.npy', 'bulgarian13.npy', 'bulgarian14.npy', 'bulgarian15.npy', 'bulgarian16.npy', 'bulgarian17.npy', 'bulgarian18.npy', 'bulgarian2.npy', 'bulgarian3.npy', 'bulgarian4.npy', 'bulgarian5.npy', 'bulgarian6.npy', 'bulgarian7.npy', 'bulgarian8.npy', 'bulgarian9.npy', 'cantonese1.npy', 'cantonese10.npy', 'cantonese11.npy', 'cantonese12.npy', 'cantonese13.npy', 'cantonese14.npy', 'cantonese15.npy', 'cantonese16.npy', 'cantonese17.npy', 'cantonese18.npy', 'cantonese19.npy', 'cantonese2.npy', 'cantonese20.npy', 'cantonese21.npy', 'cantonese22.npy', 'cantonese23.npy', 'cantonese3.npy', 'cantonese4.npy', 'cantonese5.npy', 'cantonese6.npy', 'cantonese7.npy', 'cantonese8.npy', 'cantonese9.npy', 'czech1.npy', 'czech2.npy', 'czech3.npy', 'czech4.npy', 'czech5.npy', 'czech6.npy', 'czech7.npy', 'czech8.npy', 'czech9.npy', 'farsi1.npy', 'farsi10.npy', 'farsi11.npy', 'farsi12.npy', 'farsi13.npy', 'farsi14.npy', 'farsi15.npy', 'farsi16.npy', 'farsi17.npy', 'farsi18.npy', 'farsi19.npy', 'farsi2.npy', 'farsi20.npy', 'farsi21.npy', 'farsi22.npy', 'farsi23.npy', 'farsi3.npy', 'farsi4.npy', 'farsi5.npy', 'farsi6.npy', 'farsi7.npy', 'farsi8.npy', 'farsi9.npy', 'greek1.npy', 'greek10.npy', 'greek11.npy', 'greek12.npy', 'greek13.npy', 'greek14.npy', 'greek15.npy', 'greek2.npy', 'greek3.npy', 'greek4.npy', 'greek5.npy', 'greek6.npy', 'greek7.npy', 'greek8.npy', 'greek9.npy', 'gujarati1.npy', 'gujarati2.npy', 'gujarati3.npy', 'gujarati4.npy', 'gujarati5.npy', 'gujarati6.npy', 'gujarati7.npy', 'gujarati8.npy', 'gujarati9.npy', 'hausa1.npy', 'hausa2.npy', 'hausa3.npy', 'hausa4.npy', 'hausa5.npy', 'hausa6.npy', 'hausa7.npy', 'hausa8.npy', 'hausa9.npy', 'hebrew1.npy', 'hebrew2.npy', 'hebrew3.npy', 'hebrew4.npy', 'hebrew5.npy', 'hebrew6.npy', 'hebrew7.npy', 'hebrew8.npy', 'hebrew9.npy', 'hindi1.npy', 'hindi10.npy', 'hindi11.npy', 'hindi12.npy', 'hindi13.npy', 'hindi14.npy', 'hindi15.npy', 'hindi16.npy', 'hindi17.npy', 'hindi18.npy', 'hindi2.npy', 'hindi3.npy', 'hindi4.npy', 'hindi5.npy', 'hindi6.npy', 'hindi7.npy', 'hindi8.npy', 'hindi9.npy', 'hungarian1.npy', 'hungarian2.npy', 'hungarian3.npy', 'hungarian4.npy', 'hungarian5.npy', 'hungarian6.npy', 'hungarian7.npy', 'hungarian8.npy', 'hungarian9.npy', 'japanese1.npy', 'japanese10.npy', 'japanese11.npy', 'japanese12.npy', 'japanese13.npy', 'japanese14.npy', 'japanese15.npy', 'japanese16.npy', 'japanese17.npy', 'japanese18.npy', 'japanese19.npy', 'japanese2.npy', 'japanese20.npy', 'japanese21.npy', 'japanese22.npy', 'japanese23.npy', 'japanese24.npy', 'japanese25.npy', 'japanese26.npy', 'japanese27.npy', 'japanese3.npy', 'japanese4.npy', 'japanese5.npy', 'japanese6.npy', 'japanese7.npy', 'japanese8.npy', 'japanese9.npy', 'kiswahili1.npy', 'kiswahili2.npy', 'kiswahili3.npy', 'kiswahili4.npy', 'kiswahili5.npy', 'kiswahili6.npy', 'kiswahili7.npy', 'kiswahili8.npy', 'kiswahili9.npy', 'kurdish1.npy', 'kurdish10.npy', 'kurdish2.npy', 'kurdish3.npy', 'kurdish4.npy', 'kurdish5.npy', 'kurdish6.npy', 'kurdish7.npy', 'kurdish8.npy', 'kurdish9.npy', 'macedonian1.npy', 'macedonian10.npy', 'macedonian11.npy', 'macedonian12.npy', 'macedonian13.npy', 'macedonian14.npy', 'macedonian15.npy', 'macedonian16.npy', 'macedonian17.npy', 'macedonian18.npy', 'macedonian19.npy', 'macedonian2.npy', 'macedonian20.npy', 'macedonian21.npy', 'macedonian22.npy', 'macedonian23.npy', 'macedonian24.npy', 'macedonian25.npy', 'macedonian26.npy', 'macedonian3.npy', 'macedonian4.npy', 'macedonian5.npy', 'macedonian6.npy', 'macedonian7.npy', 'macedonian8.npy', 'macedonian9.npy', 'miskito1.npy', 'miskito10.npy', 'miskito11.npy', 'miskito2.npy', 'miskito3.npy', 'miskito4.npy', 'miskito5.npy', 'miskito6.npy', 'miskito7.npy', 'miskito8.npy', 'miskito9.npy', 'mongolian1.npy', 'mongolian2.npy', 'mongolian3.npy', 'mongolian4.npy', 'mongolian5.npy', 'mongolian6.npy', 'mongolian7.npy', 'mongolian8.npy', 'mongolian9.npy', 'nepali1.npy', 'nepali10.npy', 'nepali11.npy', 'nepali12.npy', 'nepali13.npy', 'nepali2.npy', 'nepali3.npy', 'nepali4.npy', 'nepali5.npy', 'nepali6.npy', 'nepali7.npy', 'nepali8.npy', 'nepali9.npy', 'pashto1.npy', 'pashto10.npy', 'pashto2.npy', 'pashto3.npy', 'pashto4.npy', 'pashto5.npy', 'pashto6.npy', 'pashto7.npy', 'pashto8.npy', 'pashto9.npy', 'punjabi1.npy', 'punjabi10.npy', 'punjabi2.npy', 'punjabi3.npy', 'punjabi4.npy', 'punjabi5.npy', 'punjabi6.npy', 'punjabi7.npy', 'punjabi8.npy', 'punjabi9.npy', 'romanian1.npy', 'romanian10.npy', 'romanian11.npy', 'romanian12.npy', 'romanian13.npy', 'romanian14.npy', 'romanian15.npy', 'romanian16.npy', 'romanian17.npy', 'romanian18.npy', 'romanian19.npy', 'romanian2.npy', 'romanian20.npy', 'romanian3.npy', 'romanian4.npy', 'romanian5.npy', 'romanian6.npy', 'romanian7.npy', 'romanian8.npy', 'romanian9.npy', 'serbian1.npy', 'serbian10.npy', 'serbian11.npy', 'serbian12.npy', 'serbian13.npy', 'serbian14.npy', 'serbian15.npy', 'serbian16.npy', 'serbian17.npy', 'serbian18.npy', 'serbian2.npy', 'serbian3.npy', 'serbian4.npy', 'serbian5.npy', 'serbian6.npy', 'serbian7.npy', 'serbian8.npy', 'serbian9.npy', 'swedish1.npy', 'swedish10.npy', 'swedish11.npy', 'swedish12.npy', 'swedish13.npy', 'swedish14.npy', 'swedish15.npy', 'swedish16.npy', 'swedish17.npy', 'swedish18.npy', 'swedish19.npy', 'swedish2.npy', 'swedish20.npy', 'swedish3.npy', 'swedish4.npy', 'swedish5.npy', 'swedish6.npy', 'swedish7.npy', 'swedish8.npy', 'swedish9.npy', 'tagalog1.npy', 'tagalog10.npy', 'tagalog11.npy', 'tagalog12.npy', 'tagalog13.npy', 'tagalog14.npy', 'tagalog15.npy', 'tagalog16.npy', 'tagalog17.npy', 'tagalog18.npy', 'tagalog2.npy', 'tagalog3.npy', 'tagalog4.npy', 'tagalog5.npy', 'tagalog6.npy', 'tagalog7.npy', 'tagalog8.npy', 'tagalog9.npy', 'thai1.npy', 'thai10.npy', 'thai11.npy', 'thai12.npy', 'thai13.npy', 'thai14.npy', 'thai15.npy', 'thai2.npy', 'thai3.npy', 'thai4.npy', 'thai5.npy', 'thai6.npy', 'thai7.npy', 'thai8.npy', 'thai9.npy', 'ukrainian1.npy', 'ukrainian10.npy', 'ukrainian11.npy', 'ukrainian2.npy', 'ukrainian3.npy', 'ukrainian4.npy', 'ukrainian5.npy', 'ukrainian6.npy', 'ukrainian7.npy', 'ukrainian8.npy', 'ukrainian9.npy', 'urdu1.npy', 'urdu10.npy', 'urdu11.npy', 'urdu12.npy', 'urdu13.npy', 'urdu14.npy', 'urdu15.npy', 'urdu16.npy', 'urdu2.npy', 'urdu3.npy', 'urdu4.npy', 'urdu5.npy', 'urdu6.npy', 'urdu7.npy', 'urdu8.npy', 'urdu9.npy', 'vietnamese1.npy', 'vietnamese10.npy', 'vietnamese11.npy', 'vietnamese12.npy', 'vietnamese13.npy', 'vietnamese14.npy', 'vietnamese15.npy', 'vietnamese16.npy', 'vietnamese17.npy', 'vietnamese18.npy', 'vietnamese19.npy', 'vietnamese2.npy', 'vietnamese20.npy', 'vietnamese21.npy', 'vietnamese22.npy', 'vietnamese3.npy', 'vietnamese4.npy', 'vietnamese5.npy', 'vietnamese6.npy', 'vietnamese7.npy', 'vietnamese8.npy', 'vietnamese9.npy']\n",
            "max length: 9988\n"
          ]
        }
      ],
      "source": [
        "write_spectra_to_disk = False\n",
        "use_full_dataset = True\n",
        "display_examples = False\n",
        "calculate_max_spectrum_length = True\n",
        "\n",
        "if write_spectra_to_disk:\n",
        "    archive_path = \"./gdrive/MyDrive/Accent_Recognition/archive\"\n",
        "    recordings_path = \"./gdrive/MyDrive/Accent_Recognition/archive/recordings/recordings\"  \n",
        "    if use_full_dataset:\n",
        "      speakers_file_name = \"speakers_all.csv\"\n",
        "    else:\n",
        "      speakers_file_name = \"speakers_half.csv\"\n",
        "    full_dataset = AccentDataset(audio_files_folder=recordings_path, \n",
        "                                 metadata_file=os.path.join(archive_path,speakers_file_name),\n",
        "                                 make_spectra=True, \n",
        "                                 language_samples_threshold = )\n",
        "    full_dataset.write_spectrograms()\n",
        "    print(\"DONE\")\n",
        "\n",
        "if display_examples:\n",
        "    af1 = af2 = None\n",
        "    af1 = full_dataset.audio['dutch10']\n",
        "    af1.plot_spectrogram()\n",
        "    af1.play_recording()\n",
        "    af2 = full_dataset.audio['korean44']\n",
        "    af2.plot_spectrogram()\n",
        "    af2.play_recording()  \n",
        "\n",
        "if calculate_max_spectrum_length:\n",
        "    spectra_folder =\"./gdrive/MyDrive/Accent_Recognition/archive/recordings/Spectra\"\n",
        "    spectra_file_names = os.listdir(spectra_folder)\n",
        "    print(spectra_file_names)\n",
        "    spectrogram_lengths = {}\n",
        "    just_lengths = []\n",
        "    for file_name in spectra_file_names:\n",
        "        spectrogram_file_full_path = os.path.join(spectra_folder, file_name)\n",
        "        spectrogram = np.load(spectrogram_file_full_path)\n",
        "        this_length = spectrogram.shape[2]\n",
        "        spectrogram_lengths[file_name] = this_length\n",
        "        just_lengths.append(spectrogram_lengths[file_name])\n",
        "        #print(this_length)\n",
        "    max_spectral_length = max(just_lengths)\n",
        "    print(f\"max length: {max_spectral_length}\" ) # 7336, now 9988"
      ],
      "id": "MMA363kFN8Yi"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHWeoAsCCFwo"
      },
      "source": [
        "# Define Filtering and Splitting Functions"
      ],
      "id": "HHWeoAsCCFwo"
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "VF2v1CdzCAA3"
      },
      "outputs": [],
      "source": [
        "def filter_metadata(metadata_unfiltered, language_samples_threshold = 30, max_samples_per_language = np.inf):\n",
        "    metadata = metadata_unfiltered[metadata_unfiltered['file_missing?'] != True]\n",
        "    samples_per_language = Counter(metadata['native_language'])    \n",
        "    filtered_languages = [language for language in samples_per_language.keys() if samples_per_language[language] >= language_samples_threshold]\n",
        "    filtered_speakers = metadata[metadata['native_language'].isin(filtered_languages)]\n",
        "    if np.isfinite(max_samples_per_language):\n",
        "      filtered_speakers = filtered_speakers.groupby('native_language').head(max_samples_per_language).reset_index(drop=True)\n",
        "    filtered_speakers.reset_index(inplace=True)\n",
        "    return filtered_speakers\n",
        "\n",
        "\n",
        "def create_train_test_split(metadata,\n",
        "                            training_fraction=.67,\n",
        "                            downsampled_number = 5,\n",
        "                            downsample_training=False):\n",
        "    unique_languages = list(set(metadata['native_language']))\n",
        "    train_indices =[]\n",
        "    test_indices = []\n",
        "    for language in unique_languages:\n",
        "        this_language = metadata[metadata['native_language'] == language]\n",
        "        this_language_male = this_language[this_language['sex']=='male']\n",
        "        this_language_female = this_language[this_language['sex']=='female']\n",
        "        traininds_male = random.sample(list(this_language_male.index), \n",
        "                                        int(training_fraction * len(this_language_male.index)))\n",
        "        traininds_female = random.sample(list(this_language_female.index), \n",
        "                                        int(training_fraction * len(this_language_female.index)))\n",
        "        traininds = traininds_male + traininds_female\n",
        "        testinds = list(set(this_language.index) - set(traininds))\n",
        "        if downsample_training:                \n",
        "            traininds = traininds_male[:downsampled_number] + traininds_female[:downsampled_number]\n",
        "        train_indices += traininds\n",
        "        test_indices += testinds\n",
        "    return sorted(train_indices), sorted(test_indices)"
      ],
      "id": "VF2v1CdzCAA3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdIVl9rSBK0k"
      },
      "source": [
        "# Define the Metadata and Target Dictionaries"
      ],
      "id": "YdIVl9rSBK0k"
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-T24JHpKBB7n",
        "outputId": "34cdc300-12ee-4ea9-c0ae-821f9c4dc59c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "english      579\n",
            "arabic       102\n",
            "dutch         47\n",
            "cantonese     23\n",
            "farsi         23\n",
            "amharic       20\n",
            "bulgarian     18\n",
            "bengali       17\n",
            "french        10\n",
            "Name: native_language, dtype: int64\n",
            "\n",
            "\n",
            "Number of missing files: 0\n",
            "\n",
            "\n",
            "english      387\n",
            "arabic        68\n",
            "dutch         30\n",
            "farsi         15\n",
            "cantonese     15\n",
            "amharic       12\n",
            "bulgarian     11\n",
            "bengali       10\n",
            "french         6\n",
            "Name: native_language, dtype: int64\n",
            "\n",
            "\n",
            "cantonese    4\n",
            "bengali      4\n",
            "dutch        4\n",
            "amharic      4\n",
            "english      4\n",
            "bulgarian    4\n",
            "arabic       4\n",
            "french       4\n",
            "farsi        4\n",
            "Name: native_language, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "##################\n",
        "# Load the metadata\n",
        "##################\n",
        "\n",
        "metadata_unfiltered = pd.read_csv(os.path.join(\"./gdrive/MyDrive/Accent_Recognition/archive\", \n",
        "                                         \"speakers_half.csv\"))\n",
        "metadata_unfiltered.drop(metadata_unfiltered.iloc[:,9:12],axis=1,inplace=True)\n",
        "\n",
        "##################\n",
        "# Produce filtered training and testing metadata dataframes\n",
        "##################\n",
        "\n",
        "balance_train_and_test = False\n",
        "if balance_train_and_test:\n",
        "  filtered_metadata = filter_metadata(metadata_unfiltered, \n",
        "                                      language_samples_threshold = 10, \n",
        "                                      max_samples_per_language=10)\n",
        "  train_indices, test_indices = create_train_test_split(filtered_metadata)\n",
        "  metadata_train = filtered_metadata.iloc[train_indices]\n",
        "  metadata_test = filtered_metadata.iloc[test_indices]\n",
        "else:\n",
        "  filtered_metadata = filter_metadata(metadata_unfiltered, \n",
        "                                      language_samples_threshold = 10, \n",
        "                                      max_samples_per_language=100) # this can be as high as 579\n",
        "  train_indices, test_indices = create_train_test_split(filtered_metadata)\n",
        "  metadata_train = filtered_metadata.iloc[train_indices]\n",
        "  metadata_test = filtered_metadata.iloc[test_indices]\n",
        "  metadata_test = filter_metadata(metadata_test, \n",
        "                                  language_samples_threshold = 4, \n",
        "                                  max_samples_per_language=4)\n",
        "\n",
        "##################\n",
        "# Define Language Target Dictionary\n",
        "##################\n",
        "\n",
        "training_languages = list(set(filtered_metadata['native_language']))\n",
        "number_of_training_languages = len(training_languages)\n",
        "training_languages_dict = dict(zip(training_languages, list(range(number_of_training_languages))))\n",
        "\n",
        "##################\n",
        "# Define Gender Target Dictionary\n",
        "##################\n",
        "\n",
        "training_genders = list(set(filtered_metadata['sex']))\n",
        "number_of_training_genders = len(training_genders)\n",
        "training_gender_dict = dict(zip(training_genders, list(range(number_of_training_genders))))\n",
        "\n",
        "\n",
        "print(\"\\n\")\n",
        "print(filtered_metadata['native_language'].value_counts())\n",
        "\n",
        "print(\"\\n\")\n",
        "print(f\"Number of missing files: {sum(filtered_metadata['file_missing?'])}\")\n",
        "\n",
        "print(\"\\n\")\n",
        "print(metadata_train['native_language'].value_counts())\n",
        "\n",
        "print(\"\\n\")\n",
        "print(metadata_test['native_language'].value_counts())\n"
      ],
      "id": "-T24JHpKBB7n"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCViYHkeYun7"
      },
      "source": [
        "#Augmentation"
      ],
      "id": "XCViYHkeYun7"
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "X7SvKWm1Yttr"
      },
      "outputs": [],
      "source": [
        "###################\n",
        "# Define functions to produce a metadata file indicating what augmentations to apply\n",
        "#\n",
        "# Must apply the augmentations in the generator following instructions in metadata file\n",
        "###################\n",
        "\n",
        "def augment_metadata(metadata_file_input, target_column='native_language', number_of_samples_per_class=-1):\n",
        "  metadata_file = metadata_file_input.copy()\n",
        "  if target_column in ['native_language','language']:\n",
        "    target_column='native_language'\n",
        "  target_value_counts = metadata_file[target_column].value_counts()\n",
        "  # use augmentation to upsample all classes to at least as many as the largest class\n",
        "  # to use less samples, create a metadata file with a lower maximum number of samples per language\n",
        "  number_of_samples_per_class = max(number_of_samples_per_class, max(target_value_counts))\n",
        "  additional_column_names = ['AddGaussianNoise_min_amplitude',\n",
        "                             'AddGaussianNoise_max_amplitude',\n",
        "                             'AddGaussianNoise_p',\n",
        "                             'TimeStretch_min_rate',\n",
        "                             'TimeStretch_max_rate',\n",
        "                             'TimeStretch_p',\n",
        "                             'PitchShift_min_semitones',\n",
        "                             'PitchShift_max_semitones',\n",
        "                             'PitchShift_p',\n",
        "                             'Shift_min_fraction',\n",
        "                             'Shift_max_fraction',\n",
        "                             'Shift_p']\n",
        "  target_column_levels = metadata_file[target_column].unique()\n",
        "  #print(f\"Unique target levels {target_column_levels}\")\n",
        "  single_level_expansions = []\n",
        "  for target_level in tqdm(target_column_levels):\n",
        "    metadata_one_class = metadata_file[metadata_file[target_column] == target_level].copy()#.reset_index()\n",
        "    metadata_one_class_expanded = metadata_one_class.iloc[[ind % metadata_one_class.shape[0] for ind in range(number_of_samples_per_class)]]\n",
        "    if additional_column_names[0] not in metadata_one_class_expanded.columns:\n",
        "      metadata_one_class_expanded[additional_column_names] = 0.0\n",
        "    for row_number in range(metadata_one_class.shape[0],metadata_one_class_expanded.shape[0]):\n",
        "      # for samples that we are going to augment, choose 1, 2, 3, or 4 augmentations to apply\n",
        "      number_of_augmentations = random.choice(range(1,5))\n",
        "      which_augmentations = sorted(random.sample(range(4),number_of_augmentations))\n",
        "      if 0 in which_augmentations:\n",
        "        metadata_one_class_expanded['AddGaussianNoise_p'].iloc[row_number] = 1\n",
        "        min_gaussian_amplitude = random.uniform(0, 0.002)\n",
        "        metadata_one_class_expanded['AddGaussianNoise_min_amplitude'].iloc[row_number] = min_gaussian_amplitude\n",
        "        metadata_one_class_expanded['AddGaussianNoise_max_amplitude'].iloc[row_number] = random.uniform(min_gaussian_amplitude, 0.03)\n",
        "      if 1 in which_augmentations:\n",
        "        metadata_one_class_expanded['TimeStretch_p'].iloc[row_number] = 1\n",
        "        metadata_one_class_expanded['TimeStretch_min_rate'].iloc[row_number] = random.uniform(.6, 1)\n",
        "        metadata_one_class_expanded['TimeStretch_max_rate'].iloc[row_number] = random.uniform(1, 1.5)\n",
        "      if 2 in which_augmentations:\n",
        "        metadata_one_class_expanded['PitchShift_p'].iloc[row_number] = 1\n",
        "        metadata_one_class_expanded['PitchShift_min_semitones'].iloc[row_number] = -4\n",
        "        metadata_one_class_expanded['PitchShift_max_semitones'].iloc[row_number] = 4\n",
        "      if 3 in which_augmentations:\n",
        "        metadata_one_class_expanded['Shift_p'].iloc[row_number] = 1\n",
        "        metadata_one_class_expanded['Shift_min_fraction'].iloc[row_number] = -.5\n",
        "        metadata_one_class_expanded['Shift_max_fraction'].iloc[row_number] = .5\n",
        "    single_level_expansions.append(metadata_one_class_expanded.reset_index(drop=True))\n",
        "  concatenated_metadata = pd.concat(single_level_expansions)\n",
        "  concatenated_metadata.reset_index(drop=True, inplace=True)\n",
        "  del concatenated_metadata['index']\n",
        "  return concatenated_metadata\n",
        "\n",
        "\n",
        "from audiomentations import Compose, AddGaussianNoise, TimeStretch, PitchShift, Shift\n",
        "\n",
        "def augment_sample(spectrogram, metadata_line):\n",
        "  aumentations_list = []\n",
        "  if metadata_line['AddGaussianNoise_p'] != 0:\n",
        "    aumentations_list.append(AddGaussianNoise(min_amplitude=metadata_line['AddGaussianNoise_min_amplitude'],\n",
        "                                              max_amplitude=metadata_line['AddGaussianNoise_max_amplitude'],\n",
        "                                              p=metadata_line['AddGaussianNoise_p']\n",
        "                                              ))\n",
        "  if metadata_line['TimeStretch_p'] != 0:\n",
        "    aumentations_list.append(TimeStretch(min_rate=metadata_line['TimeStretch_min_rate'],\n",
        "                                         max_rate=metadata_line['TimeStretch_max_rate'],\n",
        "                                         p=metadata_line['TimeStretch_p']\n",
        "                                         ))\n",
        "  if metadata_line['PitchShift_p'] != 0:\n",
        "    aumentations_list.append(PitchShift(min_semitones=metadata_line['PitchShift_min_semitones'],\n",
        "                                        max_semitones=metadata_line['PitchShift_max_semitones'],\n",
        "                                        p=metadata_line['PitchShift_p']\n",
        "                                        ))\n",
        "  if metadata_line['Shift_p'] != 0:\n",
        "    aumentations_list.append(Shift(min_fraction=metadata_line['Shift_min_fraction'], \n",
        "                                   max_fraction=metadata_line['Shift_max_fraction'], \n",
        "                                   p=metadata_line['Shift_p']\n",
        "                                   ))\n",
        "  augment = Compose(aumentations_list)\n",
        "  #Audio data must be of type numpy.ndarray\n",
        "  if not isinstance(spectrogram,np.ndarray):\n",
        "    print(f\"Spectrogram is not numpy, it is {type(spectrogram)} , converting to numpy...\")\n",
        "    augmented_spectrogram = augment(samples=spectrogram.numpy(), sample_rate=44100)\n",
        "  else:  \n",
        "    augmented_spectrogram = augment(samples=spectrogram, sample_rate=44100)\n",
        "  return augmented_spectrogram\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  #return metadata_file\n",
        "# ###################\n",
        "# # Pytorch example\n",
        "# # taken from \n",
        "# # https://github.com/asteroid-team/torch-audiomentations\n",
        "# ###################\n",
        "\n",
        "# import torch\n",
        "# from torch_audiomentations import Compose, Gain, PolarityInversion\n",
        "\n",
        "\n",
        "# # Initialize augmentation callable\n",
        "# apply_augmentation = Compose(\n",
        "#     transforms=[\n",
        "#         Gain(\n",
        "#             min_gain_in_db=-15.0,\n",
        "#             max_gain_in_db=5.0,\n",
        "#             p=0.5,\n",
        "#         ),\n",
        "#         PolarityInversion(p=0.5)\n",
        "#     ]\n",
        "# )\n",
        "\n",
        "# torch_device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# # Make an example tensor with white noise.\n",
        "# # This tensor represents 8 audio snippets with 2 channels (stereo) and 2 s of 16 kHz audio.\n",
        "# audio_samples = torch.rand(size=(8, 2, 32000), dtype=torch.float32, device=torch_device) - 0.5\n",
        "\n",
        "# # Apply augmentation. This varies the gain and polarity of (some of)\n",
        "# # the audio snippets in the batch independently.\n",
        "# perturbed_audio_samples = apply_augmentation(audio_samples, sample_rate=16000)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ###################\n",
        "# # audiomentations example\n",
        "# # taken from \n",
        "# # https://github.com/iver56/audiomentations\n",
        "# ###################\n",
        "\n",
        "# from audiomentations import Compose, AddGaussianNoise, TimeStretch, PitchShift, Shift\n",
        "# import numpy as np\n",
        "\n",
        "# augment = Compose([\n",
        "#     AddGaussianNoise(min_amplitude=0.001, max_amplitude=0.015, p=0.5),\n",
        "#     TimeStretch(min_rate=0.8, max_rate=1.25, p=0.5),\n",
        "#     PitchShift(min_semitones=-4, max_semitones=4, p=0.5),\n",
        "#     Shift(min_fraction=-0.5, max_fraction=0.5, p=0.5),\n",
        "# ])\n",
        "\n",
        "# # Generate 2 seconds of dummy audio for the sake of example\n",
        "# samples = np.random.uniform(low=-0.2, high=0.2, size=(32000,)).astype(np.float32)\n",
        "\n",
        "# # Augment/transform/perturb the audio data\n",
        "# augmented_samples = augment(samples=samples, sample_rate=16000)"
      ],
      "id": "X7SvKWm1Yttr"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "OB0_DGYfDQIM",
        "outputId": "9d777dd8-8587-4b77-e9cc-754c2ced0ce9"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-416a8e365018>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmetadata_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmdt2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdata_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAccentDatasetBatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./gdrive/MyDrive/Accent_Recognition/archive/recordings/recordings\"\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mmetadata_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mbatch_file_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfile_number\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'mdt2' is not defined"
          ]
        }
      ],
      "source": [
        "\n",
        "# metadata_batch = mdt2.iloc[-32:,:]\n",
        "# data_batch = AccentDatasetBatch(\"./gdrive/MyDrive/Accent_Recognition/archive/recordings/recordings\" , metadata_batch)\n",
        "# batch_file_names = list(data_batch.audio.keys())\n",
        "\n",
        "# file_number = 0\n",
        "# single_audio_file = data_batch.audio[batch_file_names[file_number]]\n",
        "# single_audio_file.load_audio_file()\n",
        "# file_waveform_unaugmented = single_audio_file.waveform\n",
        "\n",
        "# print(metadata_batch.iloc[file_number,:])\n",
        "\n",
        "# file_waveform = augment_sample(file_waveform_unaugmented, metadata_batch.iloc[file_number,:])\n",
        "\n",
        "# print(file_waveform_unaugmented.shape)\n",
        "# print(file_waveform.shape)\n",
        "\n",
        "# play_audio(file_waveform_unaugmented, 44100)\n",
        "# play_audio(file_waveform, 44100)\n"
      ],
      "id": "OB0_DGYfDQIM"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1BO8YaqIwf_",
        "outputId": "0c0c4fde-d687-4c58-ca60-584ac28b503b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# print(type(file_waveform_unaugmented))\n",
        "# print(type(file_waveform))\n",
        "# isinstance(file_waveform,np.ndarray)\n",
        "# isinstance(file_waveform_unaugmented,np.ndarray)"
      ],
      "id": "A1BO8YaqIwf_"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Rjw_a47c7ou",
        "outputId": "cfe153c7-598f-4f14-ba5e-22bd660347a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "age                                           29.0\n",
            "age_onset                                     19.0\n",
            "birthplace                        gonder, ethiopia\n",
            "filename                                 amharic10\n",
            "native_language                            amharic\n",
            "sex                                         female\n",
            "speakerid                                      998\n",
            "country                                   ethiopia\n",
            "file_missing?                                False\n",
            "AddGaussianNoise_min_amplitude                 0.0\n",
            "AddGaussianNoise_max_amplitude                 0.0\n",
            "AddGaussianNoise_p                             0.0\n",
            "TimeStretch_min_rate                           0.0\n",
            "TimeStretch_max_rate                           0.0\n",
            "TimeStretch_p                                  0.0\n",
            "PitchShift_min_semitones                       0.0\n",
            "PitchShift_max_semitones                       0.0\n",
            "PitchShift_p                                   0.0\n",
            "Shift_min_fraction                             0.0\n",
            "Shift_max_fraction                             0.0\n",
            "Shift_p                                        0.0\n",
            "Name: 0, dtype: object\n"
          ]
        }
      ],
      "source": [
        "# metadata_train\n",
        "# metadata_file = metadata_train\n",
        "# target_column='native_language'\n",
        "# target_value_counts = metadata_file[target_column].value_counts()\n",
        "# #print(target_value_counts)\n",
        "# print(max(target_value_counts))\n",
        "\n",
        "# mdt2 = augment_metadata(metadata_file_input = metadata_train, target_column='native_language',number_of_samples_per_class=-1)\n",
        "# mdt2\n",
        "\n",
        "# print(mdt2.iloc[0,:])"
      ],
      "id": "_Rjw_a47c7ou"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfyVOxrY-sYv"
      },
      "source": [
        "# Cutom Generator Class\n"
      ],
      "id": "wfyVOxrY-sYv"
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "baCFzaMjofix"
      },
      "outputs": [],
      "source": [
        "# create data generator class\n",
        "# following pattern from here: https://medium.com/analytics-vidhya/write-your-own-custom-data-generator-for-tensorflow-keras-1252b64e41c3\n",
        "\n",
        "#import tensorflow as tf\n",
        "\n",
        "class CustomDataGen(tf.keras.utils.Sequence):\n",
        "    \n",
        "    def __init__(self,\n",
        "                target_dict,\n",
        "                metadata,\n",
        "                target = 'sex', \n",
        "                batch_size=samples_per_batch, \n",
        "                spectrogram_max_length=spectrogram_max_length,\n",
        "                number_of_mels=number_of_mels,\n",
        "                randomize=True,\n",
        "                use_augmentation=False):\n",
        "        self.target_dict = target_dict \n",
        "        self.target = target\n",
        "        self.use_augmentation = use_augmentation\n",
        "        if self.use_augmentation:\n",
        "          self.metadata = augment_metadata(metadata_file_input=metadata, \n",
        "                                           target_column=target,\n",
        "                                           number_of_samples_per_class=-1)\n",
        "        else:\n",
        "          self.metadata = metadata\n",
        "        self.number_of_inputs = self.metadata.shape[0]\n",
        "        self.file_names = list(self.metadata['filename'])\n",
        "        self.spectrogram_max_length = spectrogram_max_length\n",
        "        self.number_of_mels = number_of_mels\n",
        "        self.batch_size = batch_size      \n",
        "        self.randomize = randomize  \n",
        "        self.recordings_path = \"./gdrive/MyDrive/Accent_Recognition/archive/recordings/recordings\"  \n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        if self.randomize:\n",
        "          L = list(range(self.number_of_inputs))\n",
        "          random.shuffle(L)\n",
        "          self.metadata = self.metadata.iloc[L].reset_index(drop=True)\n",
        "   \n",
        "    def __getitem__(self, index):\n",
        "        # The role of __getitem__ method is to generate one batch of data.\n",
        "        number_of_inputs = self.metadata.shape[0]  \n",
        "        L=list(range(number_of_inputs))\n",
        "        metadata_batch = self.metadata.iloc[index * self.batch_size:(index + 1) * self.batch_size]\n",
        "        data_batch = AccentDatasetBatch(self.recordings_path, metadata_batch)\n",
        "        batch_file_names = list(data_batch.audio.keys())\n",
        "        number_of_mels = self.number_of_mels\n",
        "        spectrogram_lengths = []\n",
        "        for file_number in range(len(batch_file_names)):\n",
        "          spectrogram_lengths.append(data_batch.audio[batch_file_names[file_number]].spectrogram.T[:,:,0].shape[0])\n",
        "        spectrogram_max_length = self.spectrogram_max_length\n",
        "        batch_inputs = np.zeros([self.batch_size, spectrogram_max_length, self.number_of_mels])\n",
        "        batch_targets = np.zeros([self.batch_size, len(self.target_dict)])\n",
        "        batch_ys = np.zeros([self.batch_size])\n",
        "        for file_number in range(len(batch_file_names)):\n",
        "          if self.use_augmentation:\n",
        "            this_audio_obj = data_batch.audio[batch_file_names[file_number]]\n",
        "            this_audio_obj.load_audio_file()\n",
        "            this_audio_obj.waveform = augment_sample(\n",
        "                this_audio_obj.waveform, \n",
        "                metadata_batch.iloc[file_number,:])\n",
        "            this_audio_obj.make_mel_spectrogram()\n",
        "            file_spectrogram = this_audio_obj.spectrogram.T[:,:,0]\n",
        "          else:\n",
        "            file_spectrogram = data_batch.audio[batch_file_names[file_number]].spectrogram.T[:,:,0]\n",
        "          batch_inputs[file_number, :spectrogram_lengths[file_number], :] = file_spectrogram  \n",
        "          if self.target == 'sex':\n",
        "            file_gender = data_batch.audio[batch_file_names[file_number]].sex\n",
        "            batch_targets[file_number, self.target_dict[file_gender]] = 1 # this is one-hot encoded\n",
        "            batch_ys = self.target_dict[file_gender] \n",
        "          elif self.target == 'language':\n",
        "            file_language = data_batch.audio[batch_file_names[file_number]].language\n",
        "            batch_targets[file_number, self.target_dict[file_language]] = 1 # this is one-hot encoded\n",
        "            batch_ys = self.target_dict[file_language] \n",
        "          else:\n",
        "            raise ValueError('target must be one of sex or language')    \n",
        "        return batch_inputs, (batch_targets,)\n",
        "        #return batch_inputs, batch_ys\n",
        "\n",
        "    def __len__(self):\n",
        "       #__len__ will return the number of batches the generator can produce and it will be floor(number_of_samples // batch_size)\n",
        "        return self.number_of_inputs // self.batch_size\n",
        "\n",
        "\n",
        "# #############\n",
        "# # Gender Generator Definition\n",
        "# #############\n",
        "\n",
        "# traingen = CustomDataGen(target_dict=training_gender_dict, \n",
        "#                           metadata=metadata_train,\n",
        "#                           target = 'sex',\n",
        "#                           batch_size=32,\n",
        "#                           spectrogram_max_length=spectrogram_max_length,\n",
        "#                           number_of_mels=number_of_mels)\n",
        "\n",
        "\n",
        "# valgen = CustomDataGen(target_dict=training_gender_dict, \n",
        "#                         metadata=metadata_test,\n",
        "#                         target = 'sex',\n",
        "#                         batch_size=32,\n",
        "#                         spectrogram_max_length=spectrogram_max_length,\n",
        "#                         number_of_mels=number_of_mels)\n"
      ],
      "id": "baCFzaMjofix"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1o9evbjF9_3C"
      },
      "source": [
        "# Language Generators"
      ],
      "id": "1o9evbjF9_3C"
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5yHpCGg9uEF",
        "outputId": "7b863b14-2982-4b5e-dec6-d374ef79af6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/9 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/site-packages/pandas/core/indexing.py:1720: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._setitem_single_column(loc, value, pi)\n",
            "/usr/local/lib/python3.7/site-packages/pandas/core/indexing.py:1637: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._setitem_single_block(indexer, value, name)\n",
            "/usr/local/lib/python3.7/site-packages/pandas/core/indexing.py:692: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  iloc._setitem_with_indexer(indexer, value, self.name)\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:10<00:00,  1.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(554, 10)\n",
            "(36, 11)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "#############\n",
        "# Language Generator Definition\n",
        "#############\n",
        "traingen_language = CustomDataGen(target_dict=training_languages_dict, \n",
        "                          metadata=metadata_train,\n",
        "                          target = 'language',\n",
        "                          batch_size=32,\n",
        "                          spectrogram_max_length=spectrogram_max_length,\n",
        "                          number_of_mels=number_of_mels,\n",
        "                          use_augmentation=True)\n",
        "\n",
        "\n",
        "valgen_language = CustomDataGen(target_dict=training_languages_dict, \n",
        "                        metadata=metadata_test,\n",
        "                        target = 'language',\n",
        "                        batch_size=32,\n",
        "                        spectrogram_max_length=spectrogram_max_length,\n",
        "                        number_of_mels=number_of_mels)\n",
        "\n",
        "# how many training batches in the full dataset?\n",
        "print(metadata_train.shape)\n",
        "print(metadata_test.shape)"
      ],
      "id": "E5yHpCGg9uEF"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nysyjNgX-F0D"
      },
      "source": [
        "# Language Model Definition"
      ],
      "id": "nysyjNgX-F0D"
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "8R_a__pA7viY"
      },
      "outputs": [],
      "source": [
        "####################\n",
        "# Language Model Definition\n",
        "####################\n",
        "\n",
        "from keras.layers.pooling import MaxPooling2D\n",
        "from keras.layers.convolutional import Conv2D\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "#from keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Input, Bidirectional, LSTM, Dropout\n",
        "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Softmax  \n",
        "#from keras.layers.embeddings import Embedding\n",
        "from keras.regularizers import l2\n",
        "from keras.models import Model\n",
        "\n",
        "\n",
        "model_language = Sequential()\n",
        "model_language.add(Conv2D(6, \n",
        "                 (5, 5), \n",
        "                 activation='relu', \n",
        "                 input_shape=(spectrogram_max_length, \n",
        "                              number_of_mels, \n",
        "                              1)))\n",
        "model_language.add(MaxPooling2D(2, 2))\n",
        "\n",
        "model_language.add(Conv2D(16, \n",
        "                 (5, 5), \n",
        "                 activation='relu'))\n",
        "model_language.add(MaxPooling2D(2, 2))\n",
        "\n",
        "model_language.add(Flatten())\n",
        "\n",
        "model_language.add(Dense(len(training_languages_dict)))\n",
        "model_language.add(Softmax())\n",
        "\n",
        "model_language.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.CategoricalCrossentropy())"
      ],
      "id": "8R_a__pA7viY"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XueFFKYEWRl-"
      },
      "source": [
        "#Callback Definitions"
      ],
      "id": "XueFFKYEWRl-"
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9-r8zuqWLtm",
        "outputId": "1fb6dd63-b839-46fe-97ea-af60b38b3e10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished\n"
          ]
        }
      ],
      "source": [
        "# Define Early Stopping Callback\n",
        "early_stopping_callback = keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss', \n",
        "    patience=10, \n",
        "    verbose=1)\n",
        "\n",
        "# Define Checkpoint Logging Callback\n",
        "language_model_filepath = './gdrive/MyDrive/Accent_Recognition/KerasModels/'\n",
        "model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
        "    os.path.join(language_model_filepath,'checkpoint'), \n",
        "    monitor='val_loss', \n",
        "    verbose=0, \n",
        "    save_best_only=False, \n",
        "    save_weights_only=False, \n",
        "    mode='auto', \n",
        "    save_freq=16)\n",
        "\n",
        "# Define Tensorboard Callback\n",
        "tensorboard_logs_directory = './gdrive/MyDrive/Accent_Recognition/KerasModels/TensorboardLogs/'\n",
        "tensorboard_logs_directory_timestamped = os.path.join(\n",
        "    tensorboard_logs_directory,\n",
        "    datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
        "    log_dir=tensorboard_logs_directory_timestamped, \n",
        "    update_freq=\"batch\")\n",
        "\n",
        "print(\"Finished\")"
      ],
      "id": "k9-r8zuqWLtm"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7S2mYBA8C6BO"
      },
      "source": [
        "#Set up mlflow for experiment tracking"
      ],
      "id": "7S2mYBA8C6BO"
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7_BZMEyalv3",
        "outputId": "ea28f05f-a934-49e1-ebb1-756a4e6616c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLflow Tracking UI: https://726a-34-133-132-66.ngrok.io\n"
          ]
        }
      ],
      "source": [
        "#!mlflow ui\n",
        "\n",
        "# navigate to http://localhost:5000/\n",
        "# there you will see the mlflow logs\n",
        "\n",
        "# set this up following example here: \n",
        "# https://medium.com/the-point-collections/intro-to-mlflow-with-colab-part-1-2-beb80c960ad9\n",
        "\n",
        "\n",
        "##############\n",
        "# Second example here:\n",
        "# https://stackoverflow.com/questions/61615818/setting-up-mlflow-on-google-colab\n",
        "#############\n",
        "#!pip install mlflow --quiet\n",
        "#!pip install pyngrok --quiet\n",
        "\n",
        "import mlflow\n",
        "\n",
        "with mlflow.start_run(run_name=\"MLflow on Colab\"):\n",
        "  mlflow.log_metric(\"m1\", 2.0)\n",
        "  mlflow.log_param(\"p1\", \"mlflow-colab\")\n",
        "\n",
        "# run tracking UI in the background\n",
        "get_ipython().system_raw(\"mlflow ui --port 5000 &\") # run tracking UI in the background\n",
        "\n",
        "\n",
        "# create remote tunnel using ngrok.com to allow local port access\n",
        "# borrowed from https://colab.research.google.com/github/alfozan/MLflow-GBRT-demo/blob/master/MLflow-GBRT-demo.ipynb#scrollTo=4h3bKHMYUIG6\n",
        "\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# Terminate open tunnels if exist\n",
        "ngrok.kill()\n",
        "\n",
        "# Setting the authtoken (optional)\n",
        "# Get your authtoken from https://dashboard.ngrok.com/auth\n",
        "# ngrok config add-authtoken 2GKET8XO5WbSNknQjUkkmzKw78d_4PPyYStn7ZF9KgfhMUhtN\n",
        "NGROK_AUTH_TOKEN = \"2GKET8XO5WbSNknQjUkkmzKw78d_4PPyYStn7ZF9KgfhMUhtN\"\n",
        "ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
        "\n",
        "# Open an HTTPs tunnel on port 5000 for http://localhost:5000\n",
        "ngrok_tunnel = ngrok.connect(addr=\"5000\", proto=\"http\", bind_tls=True)\n",
        "print(\"MLflow Tracking UI:\", ngrok_tunnel.public_url)\n"
      ],
      "id": "C7_BZMEyalv3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAhcDVM3fss4"
      },
      "source": [
        "#Launch Tensorboard "
      ],
      "id": "JAhcDVM3fss4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hNyeAd2AfrlN"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir=$tensorboard_logs_directory_timestamped serve"
      ],
      "id": "hNyeAd2AfrlN"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ezut0jc-PrM"
      },
      "source": [
        "# Language Model Training"
      ],
      "id": "2ezut0jc-PrM"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CA75BZmg8M0P",
        "outputId": "b9a480d5-2337-478a-8a01-d7d745d1f902"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/site-packages/mlflow/utils/autologging_utils/__init__.py:416: FutureWarning: Autologging support for keras >= 2.6.0 has been deprecated and will be removed in a future MLflow release. Use `mlflow.tensorflow.autolog()` instead.\n",
            "  return _autolog(*args, **kwargs)\n",
            "2022/10/21 20:24:19 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '87f459e6a58048839fe7bc025c0cab65', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current keras workflow\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:00<00:00, 2703.77it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:00<00:00, 271.59it/s]\n",
            "/usr/local/lib/python3.7/dist-packages/torchaudio/functional/functional.py:540: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (128) may be set too high. Or, the value for `n_freqs` (513) may be set too low.\n",
            "  \"At least one mel filterbank has all zero values. \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:00<00:00, 2464.52it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00, 10.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:00<00:00, 1262.95it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:02<00:00, 14.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "  1/108 [..............................] - ETA: 1:28:13 - loss: 1.0861Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:00<00:00, 1115.42it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:00<00:00, 243.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r  2/108 [..............................] - ETA: 19:29 - loss: 8.3384  Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:00<00:00, 1354.16it/s]\n",
            "  3%|â–Ž         | 1/32 [00:00<00:06,  4.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r  3/108 [..............................] - ETA: 32:20 - loss: 7.5905"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:01<00:00, 23.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:00<00:00, 1198.72it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:00<00:00, 306.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r  4/108 [>.............................] - ETA: 28:53 - loss: 8.7476Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:00<00:00, 1338.90it/s]\n",
            "  0%|          | 0/32 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r  5/108 [>.............................] - ETA: 25:42 - loss: 8.6313"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:06<00:00,  4.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:00<00:00, 1140.03it/s]\n",
            "  3%|â–Ž         | 1/32 [00:00<00:05,  5.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r  6/108 [>.............................] - ETA: 27:10 - loss: 20.3713"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:07<00:00,  4.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:00<00:00, 1216.45it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:00<00:00, 226.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r  7/108 [>.............................] - ETA: 42:33 - loss: 25.7969Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:00<00:00, 1268.39it/s]\n",
            " 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 26/32 [00:00<00:00, 249.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r  8/108 [=>............................] - ETA: 43:06 - loss: 23.0095"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:00<00:00, 37.41it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:00<00:00, 798.47it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:00<00:00, 237.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r  9/108 [=>............................] - ETA: 47:39 - loss: 23.7184Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:00<00:00, 1131.60it/s]\n",
            "  0%|          | 0/32 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 10/108 [=>............................] - ETA: 43:43 - loss: 21.3506"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:02<00:00, 13.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:00<00:00, 1149.62it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:00<00:00, 237.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 11/108 [==>...........................] - ETA: 42:13 - loss: 20.6024Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:00<00:00, 1158.94it/s]\n",
            "  0%|          | 0/32 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 12/108 [==>...........................] - ETA: 41:57 - loss: 19.4238"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:06<00:00,  4.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:00<00:00, 1373.99it/s]\n",
            "  0%|          | 0/32 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 13/108 [==>...........................] - ETA: 48:39 - loss: 18.0207"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:04<00:00,  6.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:00<00:00, 1532.55it/s]\n",
            "  3%|â–Ž         | 1/32 [00:00<00:06,  5.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 14/108 [==>...........................] - ETA: 45:59 - loss: 17.0529"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:06<00:00,  4.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:00<00:00, 1347.13it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:00<00:00, 215.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 15/108 [===>..........................] - ETA: 47:30 - loss: 17.6079Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:00<00:00, 814.13it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:00<00:00, 171.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: ./gdrive/MyDrive/Accent_Recognition/KerasModels/checkpoint/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: ./gdrive/MyDrive/Accent_Recognition/KerasModels/checkpoint/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 16/108 [===>..........................] - ETA: 46:18 - loss: 16.8160"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchaudio/functional/functional.py:540: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (128) may be set too high. Or, the value for `n_freqs` (513) may be set too low.\n",
            "  \"At least one mel filterbank has all zero values. \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:00<00:00, 1232.67it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:00<00:00, 232.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 17/108 [===>..........................] - ETA: 44:34 - loss: 16.0723Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:00<00:00, 1425.45it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:00<00:00, 219.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 18/108 [====>.........................] - ETA: 42:50 - loss: 15.2942Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:00<00:00, 1230.73it/s]\n",
            "  3%|â–Ž         | 1/32 [00:00<00:07,  4.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 19/108 [====>.........................] - ETA: 41:38 - loss: 14.5706"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:08<00:00,  3.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:00<00:00, 1305.54it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:00<00:00, 226.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 20/108 [====>.........................] - ETA: 40:31 - loss: 13.8503Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:00<00:00, 972.60it/s]\n",
            "  0%|          | 0/32 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 21/108 [====>.........................] - ETA: 38:57 - loss: 13.4481"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00, 10.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:00<00:00, 1202.59it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:00<00:00, 224.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 22/108 [=====>........................] - ETA: 38:59 - loss: 12.9746Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:00<00:00, 1085.68it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:00<00:00, 246.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 23/108 [=====>........................] - ETA: 38:34 - loss: 12.6195Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:00<00:00, 1228.16it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:00<00:00, 246.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 24/108 [=====>........................] - ETA: 37:56 - loss: 12.3178Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:00<00:00, 1294.55it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:00<00:00, 217.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 25/108 [=====>........................] - ETA: 38:42 - loss: 11.9876\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:00<00:00, 1249.48it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:00<00:00, 218.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 26/108 [======>.......................] - ETA: 37:41 - loss: 11.6393Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:00<00:00, 1175.84it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:00<00:00, 239.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 27/108 [======>.......................] - ETA: 36:34 - loss: 11.3038Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:00<00:00, 1134.90it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:00<00:00, 217.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 28/108 [======>.......................] - ETA: 34:50 - loss: 10.9938Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:00<00:00, 1265.49it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:00<00:00, 239.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 29/108 [=======>......................] - ETA: 36:15 - loss: 10.6719Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:00<00:00, 1294.11it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:00<00:00, 219.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 30/108 [=======>......................] - ETA: 36:05 - loss: 10.3548\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:00<00:00, 1083.02it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:00<00:00, 159.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 31/108 [=======>......................] - ETA: 36:42 - loss: 10.0660"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:00<00:00, 1108.15it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:00<00:00, 248.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: ./gdrive/MyDrive/Accent_Recognition/KerasModels/checkpoint/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: ./gdrive/MyDrive/Accent_Recognition/KerasModels/checkpoint/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 32/108 [=======>......................] - ETA: 36:03 - loss: 9.7752 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchaudio/functional/functional.py:540: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (128) may be set too high. Or, the value for `n_freqs` (513) may be set too low.\n",
            "  \"At least one mel filterbank has all zero values. \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:00<00:00, 1503.45it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:00<00:00, 181.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 33/108 [========>.....................] - ETA: 34:47 - loss: 9.5062Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:00<00:00, 1385.07it/s]\n",
            "  3%|â–Ž         | 1/32 [00:00<00:04,  6.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 34/108 [========>.....................] - ETA: 33:54 - loss: 9.2452"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:06<00:00,  4.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:00<00:00, 1112.46it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:00<00:00, 195.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 35/108 [========>.....................] - ETA: 33:05 - loss: 9.0222Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:00<00:00, 1330.57it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:00<00:00, 240.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 36/108 [=========>....................] - ETA: 32:40 - loss: 8.8043Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:00<00:00, 1344.46it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:00<00:00, 212.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 37/108 [=========>....................] - ETA: 31:42 - loss: 8.5841Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:00<00:00, 1066.64it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:00<00:00, 215.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 38/108 [=========>....................] - ETA: 31:01 - loss: 8.3876Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:00<00:00, 878.55it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:00<00:00, 185.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 39/108 [=========>....................] - ETA: 30:06 - loss: 8.1901Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:00<00:00, 1316.61it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:00<00:00, 244.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 40/108 [==========>...................] - ETA: 29:13 - loss: 8.0039Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:00<00:00, 1115.84it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:00<00:00, 201.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 41/108 [==========>...................] - ETA: 29:01 - loss: 7.8457Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:00<00:00, 1040.45it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:00<00:00, 199.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 42/108 [==========>...................] - ETA: 28:32 - loss: 7.6862Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:00<00:00, 1071.65it/s]\n",
            "  3%|â–Ž         | 1/32 [00:00<00:06,  4.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 43/108 [==========>...................] - ETA: 28:13 - loss: 7.5225"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:06<00:00,  4.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:00<00:00, 1499.94it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:00<00:00, 201.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 44/108 [===========>..................] - ETA: 27:34 - loss: 7.3933Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:00<00:00, 1183.18it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:00<00:00, 206.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 45/108 [===========>..................] - ETA: 27:36 - loss: 7.2602Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:00<00:00, 1003.42it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:00<00:00, 195.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 46/108 [===========>..................] - ETA: 26:58 - loss: 7.1286Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:00<00:00, 1534.00it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:00<00:00, 198.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 47/108 [============>.................] - ETA: 26:15 - loss: 7.0043Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n",
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:00<00:00, 957.41it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:00<00:00, 201.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: ./gdrive/MyDrive/Accent_Recognition/KerasModels/checkpoint/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: ./gdrive/MyDrive/Accent_Recognition/KerasModels/checkpoint/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 48/108 [============>.................] - ETA: 25:43 - loss: 6.8702"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchaudio/functional/functional.py:540: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (128) may be set too high. Or, the value for `n_freqs` (513) may be set too low.\n",
            "  \"At least one mel filterbank has all zero values. \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spectrogram is not numpy, it is <class 'torch.Tensor'> , converting to numpy...\n"
          ]
        }
      ],
      "source": [
        "################################################\n",
        "# Model Training\n",
        "# Language Model\n",
        "################################################\n",
        "\n",
        "valgen_language = CustomDataGen(target_dict=training_languages_dict, \n",
        "                        metadata=metadata_test,\n",
        "                        target = 'language',\n",
        "                        batch_size=32,\n",
        "                        spectrogram_max_length=spectrogram_max_length,\n",
        "                        number_of_mels=number_of_mels)\n",
        "\n",
        "model = None\n",
        "model = model_language\n",
        "\n",
        "num_epochs = 50\n",
        "\n",
        "mlflow.keras.autolog()\n",
        "training_history = model.fit(traingen_language,\n",
        "          validation_data=valgen_language,\n",
        "          callbacks=[early_stopping_callback, \n",
        "                     model_checkpoint_callback,\n",
        "                     tensorboard_callback],\n",
        "          epochs=num_epochs)\n",
        "\n",
        "\n",
        "# Save the final weights\n",
        "model.save(os.path.join(language_model_filepath,'LanguageModel'))"
      ],
      "id": "CA75BZmg8M0P"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-x8ygiqFfGP"
      },
      "source": [
        "# Get Predictions"
      ],
      "id": "G-x8ygiqFfGP"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRcOjOMRDRy1",
        "outputId": "45c48407-6a1e-433d-fa50-24707c305712"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:00<00:00, 3751.33it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:00<00:00, 318.44it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 1014.34it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 89.65it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 382.62it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 129.50it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 1100.58it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 218.89it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\r 1/36 [..............................] - ETA: 12s"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 846.99it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 124.41it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 440.49it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 128.54it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 4/36 [==>...........................] - ETA: 0s "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 1600.27it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 256.49it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 780.63it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 149.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 6/36 [====>.........................] - ETA: 0s"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 1135.74it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 153.12it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 1362.23it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 129.96it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 8/36 [=====>........................] - ETA: 0s"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 1973.79it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 173.11it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 1547.71it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 139.49it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r10/36 [=======>......................] - ETA: 0s"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 1411.27it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 157.11it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 1947.22it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 134.92it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r12/36 [=========>....................] - ETA: 0s"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 1698.10it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 118.83it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 925.89it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 144.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r14/36 [==========>...................] - ETA: 0s"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 347.47it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 136.12it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 1960.87it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 139.31it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r16/36 [============>.................] - ETA: 0s"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 1952.66it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 143.09it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 1376.99it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 184.83it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r18/36 [==============>...............] - ETA: 0s"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 1242.02it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 152.61it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 1133.90it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 189.67it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 763.57it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 96.76it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r21/36 [================>.............] - ETA: 0s"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 420.95it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 174.10it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 1600.88it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 120.85it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r23/36 [==================>...........] - ETA: 0s"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 1241.65it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 165.48it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 1298.14it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 84.27it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/36 [===================>..........] - ETA: 0s"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 2048.00it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 117.26it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 1049.89it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 141.37it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r27/36 [=====================>........] - ETA: 0s"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 1825.99it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 141.58it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 1638.40it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 261.59it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29/36 [=======================>......] - ETA: 0s"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 1244.97it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 116.50it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 1821.23it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 176.83it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31/36 [========================>.....] - ETA: 0s"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 1271.00it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 120.93it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 481.33it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 161.49it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r33/36 [==========================>...] - ETA: 0s"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 1202.15it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 154.66it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 419.85it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 138.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r35/36 [============================>.] - ETA: 0s"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 1784.81it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 157.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r36/36 [==============================] - 1s 31ms/step\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sb\n",
        "\n",
        "####################\n",
        "# get ground truth\n",
        "####################\n",
        "\n",
        "valgen_language = CustomDataGen(target_dict=training_languages_dict, \n",
        "                        metadata=metadata_test,\n",
        "                        target = 'language',\n",
        "                        batch_size=metadata_test.shape[0],\n",
        "                        spectrogram_max_length=spectrogram_max_length,\n",
        "                        number_of_mels=number_of_mels)\n",
        "\n",
        "ground_truth_full = valgen_language.__getitem__(0)\n",
        "ground_truth = ground_truth_full[1][0]\n",
        "\n",
        "#ground_truth_categorical = [np.argmax(ground_truth[1][ind,:]) for ind in range(ground_truth[1].shape[0])]\n",
        "ground_truth_categorical = [np.argmax(ground_truth[ind,:]) for \n",
        "                            ind in range(ground_truth.shape[0])]\n",
        "\n",
        "\n",
        "valgen_language = CustomDataGen(target_dict=training_languages_dict, \n",
        "                        metadata=metadata_test,\n",
        "                        target = 'language',\n",
        "                        batch_size=1,\n",
        "                        spectrogram_max_length=spectrogram_max_length,\n",
        "                        number_of_mels=number_of_mels)\n",
        "\n",
        "\n",
        "\n",
        "####################\n",
        "# generate predictions\n",
        "####################\n",
        "\n",
        "\n",
        "predictions = model.predict(valgen_language)\n",
        "\n",
        "predictions_categorical = [np.argmax(predictions[ind,:]) for \n",
        "                           ind in range(predictions.shape[0])]\n",
        "# print(predictions_categorical)\n",
        "\n",
        "\n",
        "# print(\"\\n\")\n",
        "# print(\"\")                            \n",
        "# print(ground_truth_categorical)\n",
        "# print(len(ground_truth_categorical))"
      ],
      "id": "ZRcOjOMRDRy1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-ndHHeB2OPM"
      },
      "source": [
        "# Display Loss History"
      ],
      "id": "f-ndHHeB2OPM"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 621
        },
        "id": "OM-9wBP6o83y",
        "outputId": "19ccc16a-d364-47e3-fecf-d220e38824df"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "####################\n",
        "# display loss history\n",
        "####################\n",
        "\n",
        "import seaborn as sb\n",
        "\n",
        "history = training_history\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('categorical cross entropy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# # Save the weights\n",
        "# model.save_weights('./checkpoints/my_checkpoint')\n",
        "\n",
        "# # Create a new model instance\n",
        "# model = create_model()\n",
        "\n",
        "# # Restore the weights\n",
        "# model.load_weights('./checkpoints/my_checkpoint')\n",
        "\n",
        "# # Evaluate the model\n",
        "# loss, acc = model.evaluate(test_images, test_labels, verbose=2)\n",
        "# print(\"Restored model, accuracy: {:5.2f}%\".format(100 * acc))"
      ],
      "id": "OM-9wBP6o83y"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09YRZRHo2ATP"
      },
      "source": [
        "#Display confusion Matrix"
      ],
      "id": "09YRZRHo2ATP"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "j7c4G-CKPOGF",
        "outputId": "92e27175-2fd1-461e-ddb8-9a19ef510810"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Diagonal elemets of the confusion matrix:\n",
            "           values\n",
            "dutch         1.0\n",
            "french        0.0\n",
            "cantonese     0.0\n",
            "amharic       0.0\n",
            "farsi         0.0\n",
            "bengali       0.0\n",
            "arabic        2.0\n",
            "english       4.0\n",
            "bulgarian     0.0\n",
            "Accuracy : 0.19444444444444445\n",
            "Chance Accuracy would be 0.1111111111111111\n",
            "Finished\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1008x1008 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "####################\n",
        "# display confusion matrix\n",
        "####################\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "preds_df = pd.DataFrame({'GroundTruth': ground_truth_categorical, 'Predictions':predictions_categorical})\n",
        "# print(preds_df)\n",
        "num_categories = len(training_languages_dict)\n",
        "confusion_matrix = np.zeros([num_categories,num_categories])\n",
        "for index in range(len(predictions_categorical)):\n",
        "  confusion_matrix[predictions_categorical[index], ground_truth_categorical[index]] += 1\n",
        "\n",
        "plt.figure(figsize=(14,14))\n",
        "tick_labels = list(training_languages_dict.keys())\n",
        "ax = sb.heatmap(confusion_matrix, \n",
        "                xticklabels=tick_labels, \n",
        "                yticklabels=tick_labels, \n",
        "                annot=False, \n",
        "                fmt='', \n",
        "                cmap='Blues')\n",
        "\n",
        "ax.set(title=\"Confusion Matrix\",\n",
        "      ylabel=\"Predictions\",\n",
        "      xlabel=\"Ground Truth\",)\n",
        " \n",
        "sb.set(font_scale=2) # set fontsize 2\n",
        "\n",
        "cm_diag=[confusion_matrix[ind,ind] for ind in range(confusion_matrix.shape[0])]\n",
        "cm_diag_df = pd.DataFrame({'values':cm_diag},index=tick_labels)\n",
        "\n",
        "# Convert the whole dataframe as a string and display\n",
        "# The scope of these changes made to\n",
        "# pandas settings are local to with statement.\n",
        "print(\"Diagonal elemets of the confusion matrix:\")\n",
        "with pd.option_context('display.max_rows', None,\n",
        "                       'display.max_columns', None,\n",
        "                       'display.precision', 3,\n",
        "                       ):\n",
        "    print(cm_diag_df)\n",
        "\n",
        "print(f\"Accuracy : {sum(cm_diag)/sum(sum(confusion_matrix))}\")\n",
        "print(f\"Chance Accuracy would be {1./len(cm_diag)}\")\n",
        "print(\"Finished\")"
      ],
      "id": "j7c4G-CKPOGF"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "hfp_Sk6qD6ro"
      ],
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}